{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Checkpoint: 08/30/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuralnet, knn, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.6.3\"Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "Warning message:\n",
      "\"package 'neuralnet' was built under R version 3.6.3\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(vcd): there is no package called 'vcd'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(vcd): there is no package called 'vcd'\nTraceback:\n",
      "1. library(vcd)"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(MASS)\n",
    "library(neuralnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'vcd' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\alsdu\\AppData\\Local\\Temp\\Rtmpc5M5zu\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'vcd' was built under R version 3.6.3\"Loading required package: grid\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"vcd\")\n",
    "library(vcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t256 obs. of  7 variables:\n",
      " $ stability: Factor w/ 2 levels \"stab\",\"xstab\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ error    : Factor w/ 4 levels \"LX\",\"MM\",\"SS\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ sign     : Factor w/ 2 levels \"nn\",\"pp\": 2 2 2 2 2 2 1 1 1 1 ...\n",
      " $ wind     : Factor w/ 2 levels \"head\",\"tail\": 1 1 1 2 2 2 1 1 1 2 ...\n",
      " $ magn     : Factor w/ 4 levels \"Light\",\"Medium\",..: 1 2 4 1 2 4 1 2 4 1 ...\n",
      " $ vis      : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ use      : Factor w/ 2 levels \"auto\",\"noauto\": 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  auto noauto \n",
       "   145    111 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(shuttle)\n",
    "str(shuttle)\n",
    "table(shuttle$use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       wind  head                    tail                  \n",
       "       magn Light Medium Out Strong Light Medium Out Strong\n",
       "use                                                        \n",
       "auto           19     19  16     18    19     19  16     19\n",
       "noauto         13     13  16     14    13     13  16     13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table1 <- structable(wind + magn ~ use, shuttle)   #vcd\n",
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mosaic(table1, shade = T) # 피값 유의하지 않음 -> 기각x-> 독립임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nIQEJEBKQACEBCfwP7UyUpybJiEoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mosaic(use ~ error + vis, shuttle) #귀무가설 기각-> 종속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "         stab xstab\n",
       "  auto     81    64\n",
       "  noauto   47    64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "        \n",
       "              stab     xstab\n",
       "  auto   0.3164062 0.2500000\n",
       "  noauto 0.1835938 0.2500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(shuttle$use, shuttle$stability)\n",
    "prop.table( table(shuttle$use, shuttle$stability) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPearson's Chi-squared test with Yates' continuity correction\n",
       "\n",
       "data:  shuttle$use and shuttle$stability\n",
       "X-squared = 4.0718, df = 1, p-value = 0.0436\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chisq.test(shuttle$use, shuttle$stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dummy Variable Object\n",
       "\n",
       "Formula: use ~ .\n",
       "7 variables, 7 factors\n",
       "Variables and levels will be separated by '.'\n",
       "A full rank encoding is used"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#신경망 모두 수치형이여야함 -> 더미로 변환\n",
    "dummies <- dummyVars (use ~. ,shuttle, fullRank = T)    #caret\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$lvls):\n",
      "\"variable 'use' is not a factor\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>stability.xstab</th><th scope=col>error.MM</th><th scope=col>error.SS</th><th scope=col>error.XL</th><th scope=col>sign.pp</th><th scope=col>wind.tail</th><th scope=col>magn.Medium</th><th scope=col>magn.Out</th><th scope=col>magn.Strong</th><th scope=col>vis.yes</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " stability.xstab & error.MM & error.SS & error.XL & sign.pp & wind.tail & magn.Medium & magn.Out & magn.Strong & vis.yes\\\\\n",
       "\\hline\n",
       "\t 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 1 & 0 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0\\\\\n",
       "\t 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0\\\\\n",
       "\t 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0\\\\\n",
       "\t 1 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0\\\\\n",
       "\t 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| stability.xstab | error.MM | error.SS | error.XL | sign.pp | wind.tail | magn.Medium | magn.Out | magn.Strong | vis.yes |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 1 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 |\n",
       "| 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 |\n",
       "| 1 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 |\n",
       "| 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 0 |\n",
       "| 1 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  stability.xstab error.MM error.SS error.XL sign.pp wind.tail magn.Medium\n",
       "1 1               0        0        0        1       0         0          \n",
       "2 1               0        0        0        1       0         1          \n",
       "3 1               0        0        0        1       0         0          \n",
       "4 1               0        0        0        1       1         0          \n",
       "5 1               0        0        0        1       1         1          \n",
       "6 1               0        0        0        1       1         0          \n",
       "  magn.Out magn.Strong vis.yes\n",
       "1 0        0           0      \n",
       "2 0        0           0      \n",
       "3 0        1           0      \n",
       "4 0        0           0      \n",
       "5 0        0           0      \n",
       "6 0        1           0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'stability.xstab'</li>\n",
       "\t<li>'error.MM'</li>\n",
       "\t<li>'error.SS'</li>\n",
       "\t<li>'error.XL'</li>\n",
       "\t<li>'sign.pp'</li>\n",
       "\t<li>'wind.tail'</li>\n",
       "\t<li>'magn.Medium'</li>\n",
       "\t<li>'magn.Out'</li>\n",
       "\t<li>'magn.Strong'</li>\n",
       "\t<li>'vis.yes'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'stability.xstab'\n",
       "\\item 'error.MM'\n",
       "\\item 'error.SS'\n",
       "\\item 'error.XL'\n",
       "\\item 'sign.pp'\n",
       "\\item 'wind.tail'\n",
       "\\item 'magn.Medium'\n",
       "\\item 'magn.Out'\n",
       "\\item 'magn.Strong'\n",
       "\\item 'vis.yes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'stability.xstab'\n",
       "2. 'error.MM'\n",
       "3. 'error.SS'\n",
       "4. 'error.XL'\n",
       "5. 'sign.pp'\n",
       "6. 'wind.tail'\n",
       "7. 'magn.Medium'\n",
       "8. 'magn.Out'\n",
       "9. 'magn.Strong'\n",
       "10. 'vis.yes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"stability.xstab\" \"error.MM\"        \"error.SS\"        \"error.XL\"       \n",
       " [5] \"sign.pp\"         \"wind.tail\"       \"magn.Medium\"     \"magn.Out\"       \n",
       " [9] \"magn.Strong\"     \"vis.yes\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuttle2<-data.frame(predict(dummies, newdata= shuttle))\n",
    "head(shuttle2)\n",
    "names(shuttle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "111 145 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuttle2$use<- ifelse(shuttle$use==\"auto\", 1, 0)\n",
    "table(shuttle2$use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "idx<-createDataPartition(shuttle2$use, p=0.7, list=F)\n",
    "train<-shuttle2[idx,]\n",
    "test<-shuttle2[-idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "use ~ stability.xstab + error.MM + error.SS + error.XL + sign.pp + \n",
       "    wind.tail + magn.Medium + magn.Out + magn.Strong + vis.yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n <- names(train)\n",
    "form <- as.formula(paste(\"use ~\", paste(n[!n %in% \"use\"], collapse = \" + \")))\n",
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>error</th><td>  0.006745424</td></tr>\n",
       "\t<tr><th scope=row>reached.threshold</th><td>  0.008028217</td></tr>\n",
       "\t<tr><th scope=row>steps</th><td>251.000000000</td></tr>\n",
       "\t<tr><th scope=row>Intercept.to.1layhid1</th><td> -2.913396291</td></tr>\n",
       "\t<tr><th scope=row>stability.xstab.to.1layhid1</th><td>  1.061971240</td></tr>\n",
       "\t<tr><th scope=row>error.MM.to.1layhid1</th><td> -1.507105083</td></tr>\n",
       "\t<tr><th scope=row>error.SS.to.1layhid1</th><td> -1.960491707</td></tr>\n",
       "\t<tr><th scope=row>error.XL.to.1layhid1</th><td> -0.557518418</td></tr>\n",
       "\t<tr><th scope=row>sign.pp.to.1layhid1</th><td> -0.362270154</td></tr>\n",
       "\t<tr><th scope=row>wind.tail.to.1layhid1</th><td> -0.093003853</td></tr>\n",
       "\t<tr><th scope=row>magn.Medium.to.1layhid1</th><td>  0.012907060</td></tr>\n",
       "\t<tr><th scope=row>magn.Out.to.1layhid1</th><td>  1.118360425</td></tr>\n",
       "\t<tr><th scope=row>magn.Strong.to.1layhid1</th><td>  0.257518170</td></tr>\n",
       "\t<tr><th scope=row>vis.yes.to.1layhid1</th><td>  4.650735293</td></tr>\n",
       "\t<tr><th scope=row>Intercept.to.1layhid2</th><td>  1.560214842</td></tr>\n",
       "\t<tr><th scope=row>stability.xstab.to.1layhid2</th><td> -1.204509288</td></tr>\n",
       "\t<tr><th scope=row>error.MM.to.1layhid2</th><td> -0.000887696</td></tr>\n",
       "\t<tr><th scope=row>error.SS.to.1layhid2</th><td>  0.904825578</td></tr>\n",
       "\t<tr><th scope=row>error.XL.to.1layhid2</th><td> -0.231255788</td></tr>\n",
       "\t<tr><th scope=row>sign.pp.to.1layhid2</th><td>  0.382575500</td></tr>\n",
       "\t<tr><th scope=row>wind.tail.to.1layhid2</th><td>  0.592086158</td></tr>\n",
       "\t<tr><th scope=row>magn.Medium.to.1layhid2</th><td>  0.058625357</td></tr>\n",
       "\t<tr><th scope=row>magn.Out.to.1layhid2</th><td> -1.051535539</td></tr>\n",
       "\t<tr><th scope=row>magn.Strong.to.1layhid2</th><td>  0.179652043</td></tr>\n",
       "\t<tr><th scope=row>vis.yes.to.1layhid2</th><td> -2.693403633</td></tr>\n",
       "\t<tr><th scope=row>Intercept.to.2layhid1</th><td>  1.615079923</td></tr>\n",
       "\t<tr><th scope=row>1layhid1.to.2layhid1</th><td>-15.554046037</td></tr>\n",
       "\t<tr><th scope=row>1layhid2.to.2layhid1</th><td> 14.713278061</td></tr>\n",
       "\t<tr><th scope=row>Intercept.to.use</th><td>-12.182285372</td></tr>\n",
       "\t<tr><th scope=row>2layhid1.to.use</th><td> 24.844204493</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\terror &   0.006745424\\\\\n",
       "\treached.threshold &   0.008028217\\\\\n",
       "\tsteps & 251.000000000\\\\\n",
       "\tIntercept.to.1layhid1 &  -2.913396291\\\\\n",
       "\tstability.xstab.to.1layhid1 &   1.061971240\\\\\n",
       "\terror.MM.to.1layhid1 &  -1.507105083\\\\\n",
       "\terror.SS.to.1layhid1 &  -1.960491707\\\\\n",
       "\terror.XL.to.1layhid1 &  -0.557518418\\\\\n",
       "\tsign.pp.to.1layhid1 &  -0.362270154\\\\\n",
       "\twind.tail.to.1layhid1 &  -0.093003853\\\\\n",
       "\tmagn.Medium.to.1layhid1 &   0.012907060\\\\\n",
       "\tmagn.Out.to.1layhid1 &   1.118360425\\\\\n",
       "\tmagn.Strong.to.1layhid1 &   0.257518170\\\\\n",
       "\tvis.yes.to.1layhid1 &   4.650735293\\\\\n",
       "\tIntercept.to.1layhid2 &   1.560214842\\\\\n",
       "\tstability.xstab.to.1layhid2 &  -1.204509288\\\\\n",
       "\terror.MM.to.1layhid2 &  -0.000887696\\\\\n",
       "\terror.SS.to.1layhid2 &   0.904825578\\\\\n",
       "\terror.XL.to.1layhid2 &  -0.231255788\\\\\n",
       "\tsign.pp.to.1layhid2 &   0.382575500\\\\\n",
       "\twind.tail.to.1layhid2 &   0.592086158\\\\\n",
       "\tmagn.Medium.to.1layhid2 &   0.058625357\\\\\n",
       "\tmagn.Out.to.1layhid2 &  -1.051535539\\\\\n",
       "\tmagn.Strong.to.1layhid2 &   0.179652043\\\\\n",
       "\tvis.yes.to.1layhid2 &  -2.693403633\\\\\n",
       "\tIntercept.to.2layhid1 &   1.615079923\\\\\n",
       "\t1layhid1.to.2layhid1 & -15.554046037\\\\\n",
       "\t1layhid2.to.2layhid1 &  14.713278061\\\\\n",
       "\tIntercept.to.use & -12.182285372\\\\\n",
       "\t2layhid1.to.use &  24.844204493\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| error |   0.006745424 |\n",
       "| reached.threshold |   0.008028217 |\n",
       "| steps | 251.000000000 |\n",
       "| Intercept.to.1layhid1 |  -2.913396291 |\n",
       "| stability.xstab.to.1layhid1 |   1.061971240 |\n",
       "| error.MM.to.1layhid1 |  -1.507105083 |\n",
       "| error.SS.to.1layhid1 |  -1.960491707 |\n",
       "| error.XL.to.1layhid1 |  -0.557518418 |\n",
       "| sign.pp.to.1layhid1 |  -0.362270154 |\n",
       "| wind.tail.to.1layhid1 |  -0.093003853 |\n",
       "| magn.Medium.to.1layhid1 |   0.012907060 |\n",
       "| magn.Out.to.1layhid1 |   1.118360425 |\n",
       "| magn.Strong.to.1layhid1 |   0.257518170 |\n",
       "| vis.yes.to.1layhid1 |   4.650735293 |\n",
       "| Intercept.to.1layhid2 |   1.560214842 |\n",
       "| stability.xstab.to.1layhid2 |  -1.204509288 |\n",
       "| error.MM.to.1layhid2 |  -0.000887696 |\n",
       "| error.SS.to.1layhid2 |   0.904825578 |\n",
       "| error.XL.to.1layhid2 |  -0.231255788 |\n",
       "| sign.pp.to.1layhid2 |   0.382575500 |\n",
       "| wind.tail.to.1layhid2 |   0.592086158 |\n",
       "| magn.Medium.to.1layhid2 |   0.058625357 |\n",
       "| magn.Out.to.1layhid2 |  -1.051535539 |\n",
       "| magn.Strong.to.1layhid2 |   0.179652043 |\n",
       "| vis.yes.to.1layhid2 |  -2.693403633 |\n",
       "| Intercept.to.2layhid1 |   1.615079923 |\n",
       "| 1layhid1.to.2layhid1 | -15.554046037 |\n",
       "| 1layhid2.to.2layhid1 |  14.713278061 |\n",
       "| Intercept.to.use | -12.182285372 |\n",
       "| 2layhid1.to.use |  24.844204493 |\n",
       "\n"
      ],
      "text/plain": [
       "                            [,1]         \n",
       "error                         0.006745424\n",
       "reached.threshold             0.008028217\n",
       "steps                       251.000000000\n",
       "Intercept.to.1layhid1        -2.913396291\n",
       "stability.xstab.to.1layhid1   1.061971240\n",
       "error.MM.to.1layhid1         -1.507105083\n",
       "error.SS.to.1layhid1         -1.960491707\n",
       "error.XL.to.1layhid1         -0.557518418\n",
       "sign.pp.to.1layhid1          -0.362270154\n",
       "wind.tail.to.1layhid1        -0.093003853\n",
       "magn.Medium.to.1layhid1       0.012907060\n",
       "magn.Out.to.1layhid1          1.118360425\n",
       "magn.Strong.to.1layhid1       0.257518170\n",
       "vis.yes.to.1layhid1           4.650735293\n",
       "Intercept.to.1layhid2         1.560214842\n",
       "stability.xstab.to.1layhid2  -1.204509288\n",
       "error.MM.to.1layhid2         -0.000887696\n",
       "error.SS.to.1layhid2          0.904825578\n",
       "error.XL.to.1layhid2         -0.231255788\n",
       "sign.pp.to.1layhid2           0.382575500\n",
       "wind.tail.to.1layhid2         0.592086158\n",
       "magn.Medium.to.1layhid2       0.058625357\n",
       "magn.Out.to.1layhid2         -1.051535539\n",
       "magn.Strong.to.1layhid2       0.179652043\n",
       "vis.yes.to.1layhid2          -2.693403633\n",
       "Intercept.to.2layhid1         1.615079923\n",
       "1layhid1.to.2layhid1        -15.554046037\n",
       "1layhid2.to.2layhid1         14.713278061\n",
       "Intercept.to.use            -12.182285372\n",
       "2layhid1.to.use              24.844204493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "fit<-neuralnet(use~. , train, hidden=c(2,1), err.fct=\"ce\", linear.output=F)\n",
    "fit$result.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-0.0058040120</td><td>0.0022578370 </td><td>0.0061042939 </td><td>2.793278e-05 </td><td>0.0018809227 </td><td>0.0022094031 </td><td>1.855860e-04 </td><td>-0.0053538239</td><td> 2.417218e-04</td><td>-0.016392872 </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-0.0007663366</td><td>0.0003444101 </td><td>0.0008416829 </td><td>2.706483e-05 </td><td>0.0002491154 </td><td>0.0002785484 </td><td>2.252078e-05 </td><td>-0.0007127678</td><td> 1.914664e-05</td><td>-0.002234323 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-0.0006637593</td><td>0.0003076139 </td><td>0.0007361950 </td><td>2.814040e-05 </td><td>0.0002159244 </td><td>0.0002386163 </td><td>1.910769e-05 </td><td>-0.0006185411</td><td> 1.401738e-05</td><td>-0.001949295 </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-0.0007314225</td><td>0.0004031544 </td><td>0.0008607337 </td><td>6.341801e-05 </td><td>0.0002389983 </td><td>0.0002446797 </td><td>1.830607e-05 </td><td>-0.0006897356</td><td>-2.256756e-06</td><td>-0.002244884 </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>-0.0444148565</td><td>0.0195765927 </td><td>0.0484852322 </td><td>1.374447e-03 </td><td>0.0144317093 </td><td>0.0162533313 </td><td>1.321717e-03 </td><td>-0.0412613771</td><td> 1.215746e-03</td><td>-0.128915111 </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>-0.0367735469</td><td>0.0164391436 </td><td>0.0403214453 </td><td>1.254416e-03 </td><td>0.0119526383 </td><td>0.0133914379 </td><td>1.084446e-03 </td><td>-0.0341918523</td><td> 9.429830e-04</td><td>-0.107084095 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "\t1 & -0.0058040120 & 0.0022578370  & 0.0061042939  & 2.793278e-05  & 0.0018809227  & 0.0022094031  & 1.855860e-04  & -0.0053538239 &  2.417218e-04 & -0.016392872 \\\\\n",
       "\t4 & -0.0007663366 & 0.0003444101  & 0.0008416829  & 2.706483e-05  & 0.0002491154  & 0.0002785484  & 2.252078e-05  & -0.0007127678 &  1.914664e-05 & -0.002234323 \\\\\n",
       "\t5 & -0.0006637593 & 0.0003076139  & 0.0007361950  & 2.814040e-05  & 0.0002159244  & 0.0002386163  & 1.910769e-05  & -0.0006185411 &  1.401738e-05 & -0.001949295 \\\\\n",
       "\t6 & -0.0007314225 & 0.0004031544  & 0.0008607337  & 6.341801e-05  & 0.0002389983  & 0.0002446797  & 1.830607e-05  & -0.0006897356 & -2.256756e-06 & -0.002244884 \\\\\n",
       "\t7 & -0.0444148565 & 0.0195765927  & 0.0484852322  & 1.374447e-03  & 0.0144317093  & 0.0162533313  & 1.321717e-03  & -0.0412613771 &  1.215746e-03 & -0.128915111 \\\\\n",
       "\t8 & -0.0367735469 & 0.0164391436  & 0.0403214453  & 1.254416e-03  & 0.0119526383  & 0.0133914379  & 1.084446e-03  & -0.0341918523 &  9.429830e-04 & -0.107084095 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | -0.0058040120 | 0.0022578370  | 0.0061042939  | 2.793278e-05  | 0.0018809227  | 0.0022094031  | 1.855860e-04  | -0.0053538239 |  2.417218e-04 | -0.016392872  |\n",
       "| 4 | -0.0007663366 | 0.0003444101  | 0.0008416829  | 2.706483e-05  | 0.0002491154  | 0.0002785484  | 2.252078e-05  | -0.0007127678 |  1.914664e-05 | -0.002234323  |\n",
       "| 5 | -0.0006637593 | 0.0003076139  | 0.0007361950  | 2.814040e-05  | 0.0002159244  | 0.0002386163  | 1.910769e-05  | -0.0006185411 |  1.401738e-05 | -0.001949295  |\n",
       "| 6 | -0.0007314225 | 0.0004031544  | 0.0008607337  | 6.341801e-05  | 0.0002389983  | 0.0002446797  | 1.830607e-05  | -0.0006897356 | -2.256756e-06 | -0.002244884  |\n",
       "| 7 | -0.0444148565 | 0.0195765927  | 0.0484852322  | 1.374447e-03  | 0.0144317093  | 0.0162533313  | 1.321717e-03  | -0.0412613771 |  1.215746e-03 | -0.128915111  |\n",
       "| 8 | -0.0367735469 | 0.0164391436  | 0.0403214453  | 1.254416e-03  | 0.0119526383  | 0.0133914379  | 1.084446e-03  | -0.0341918523 |  9.429830e-04 | -0.107084095  |\n",
       "\n"
      ],
      "text/plain": [
       "  [,1]          [,2]         [,3]         [,4]         [,5]        \n",
       "1 -0.0058040120 0.0022578370 0.0061042939 2.793278e-05 0.0018809227\n",
       "4 -0.0007663366 0.0003444101 0.0008416829 2.706483e-05 0.0002491154\n",
       "5 -0.0006637593 0.0003076139 0.0007361950 2.814040e-05 0.0002159244\n",
       "6 -0.0007314225 0.0004031544 0.0008607337 6.341801e-05 0.0002389983\n",
       "7 -0.0444148565 0.0195765927 0.0484852322 1.374447e-03 0.0144317093\n",
       "8 -0.0367735469 0.0164391436 0.0403214453 1.254416e-03 0.0119526383\n",
       "  [,6]         [,7]         [,8]          [,9]          [,10]       \n",
       "1 0.0022094031 1.855860e-04 -0.0053538239  2.417218e-04 -0.016392872\n",
       "4 0.0002785484 2.252078e-05 -0.0007127678  1.914664e-05 -0.002234323\n",
       "5 0.0002386163 1.910769e-05 -0.0006185411  1.401738e-05 -0.001949295\n",
       "6 0.0002446797 1.830607e-05 -0.0006897356 -2.256756e-06 -0.002244884\n",
       "7 0.0162533313 1.321717e-03 -0.0412613771  1.215746e-03 -0.128915111\n",
       "8 0.0133914379 1.084446e-03 -0.0341918523  9.429830e-04 -0.107084095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(  fit$ generalized.weights[[1]]  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-0.0058040120</td><td>0.0022578370 </td><td>0.0061042939 </td><td>2.793278e-05 </td><td>0.0018809227 </td><td>0.0022094031 </td><td>1.855860e-04 </td><td>-0.0053538239</td><td> 2.417218e-04</td><td>-0.016392872 </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-0.0007663366</td><td>0.0003444101 </td><td>0.0008416829 </td><td>2.706483e-05 </td><td>0.0002491154 </td><td>0.0002785484 </td><td>2.252078e-05 </td><td>-0.0007127678</td><td> 1.914664e-05</td><td>-0.002234323 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-0.0006637593</td><td>0.0003076139 </td><td>0.0007361950 </td><td>2.814040e-05 </td><td>0.0002159244 </td><td>0.0002386163 </td><td>1.910769e-05 </td><td>-0.0006185411</td><td> 1.401738e-05</td><td>-0.001949295 </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-0.0007314225</td><td>0.0004031544 </td><td>0.0008607337 </td><td>6.341801e-05 </td><td>0.0002389983 </td><td>0.0002446797 </td><td>1.830607e-05 </td><td>-0.0006897356</td><td>-2.256756e-06</td><td>-0.002244884 </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>-0.0444148565</td><td>0.0195765927 </td><td>0.0484852322 </td><td>1.374447e-03 </td><td>0.0144317093 </td><td>0.0162533313 </td><td>1.321717e-03 </td><td>-0.0412613771</td><td> 1.215746e-03</td><td>-0.128915111 </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>-0.0367735469</td><td>0.0164391436 </td><td>0.0403214453 </td><td>1.254416e-03 </td><td>0.0119526383 </td><td>0.0133914379 </td><td>1.084446e-03 </td><td>-0.0341918523</td><td> 9.429830e-04</td><td>-0.107084095 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "\t1 & -0.0058040120 & 0.0022578370  & 0.0061042939  & 2.793278e-05  & 0.0018809227  & 0.0022094031  & 1.855860e-04  & -0.0053538239 &  2.417218e-04 & -0.016392872 \\\\\n",
       "\t4 & -0.0007663366 & 0.0003444101  & 0.0008416829  & 2.706483e-05  & 0.0002491154  & 0.0002785484  & 2.252078e-05  & -0.0007127678 &  1.914664e-05 & -0.002234323 \\\\\n",
       "\t5 & -0.0006637593 & 0.0003076139  & 0.0007361950  & 2.814040e-05  & 0.0002159244  & 0.0002386163  & 1.910769e-05  & -0.0006185411 &  1.401738e-05 & -0.001949295 \\\\\n",
       "\t6 & -0.0007314225 & 0.0004031544  & 0.0008607337  & 6.341801e-05  & 0.0002389983  & 0.0002446797  & 1.830607e-05  & -0.0006897356 & -2.256756e-06 & -0.002244884 \\\\\n",
       "\t7 & -0.0444148565 & 0.0195765927  & 0.0484852322  & 1.374447e-03  & 0.0144317093  & 0.0162533313  & 1.321717e-03  & -0.0412613771 &  1.215746e-03 & -0.128915111 \\\\\n",
       "\t8 & -0.0367735469 & 0.0164391436  & 0.0403214453  & 1.254416e-03  & 0.0119526383  & 0.0133914379  & 1.084446e-03  & -0.0341918523 &  9.429830e-04 & -0.107084095 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1 | -0.0058040120 | 0.0022578370  | 0.0061042939  | 2.793278e-05  | 0.0018809227  | 0.0022094031  | 1.855860e-04  | -0.0053538239 |  2.417218e-04 | -0.016392872  |\n",
       "| 4 | -0.0007663366 | 0.0003444101  | 0.0008416829  | 2.706483e-05  | 0.0002491154  | 0.0002785484  | 2.252078e-05  | -0.0007127678 |  1.914664e-05 | -0.002234323  |\n",
       "| 5 | -0.0006637593 | 0.0003076139  | 0.0007361950  | 2.814040e-05  | 0.0002159244  | 0.0002386163  | 1.910769e-05  | -0.0006185411 |  1.401738e-05 | -0.001949295  |\n",
       "| 6 | -0.0007314225 | 0.0004031544  | 0.0008607337  | 6.341801e-05  | 0.0002389983  | 0.0002446797  | 1.830607e-05  | -0.0006897356 | -2.256756e-06 | -0.002244884  |\n",
       "| 7 | -0.0444148565 | 0.0195765927  | 0.0484852322  | 1.374447e-03  | 0.0144317093  | 0.0162533313  | 1.321717e-03  | -0.0412613771 |  1.215746e-03 | -0.128915111  |\n",
       "| 8 | -0.0367735469 | 0.0164391436  | 0.0403214453  | 1.254416e-03  | 0.0119526383  | 0.0133914379  | 1.084446e-03  | -0.0341918523 |  9.429830e-04 | -0.107084095  |\n",
       "\n"
      ],
      "text/plain": [
       "  [,1]          [,2]         [,3]         [,4]         [,5]        \n",
       "1 -0.0058040120 0.0022578370 0.0061042939 2.793278e-05 0.0018809227\n",
       "4 -0.0007663366 0.0003444101 0.0008416829 2.706483e-05 0.0002491154\n",
       "5 -0.0006637593 0.0003076139 0.0007361950 2.814040e-05 0.0002159244\n",
       "6 -0.0007314225 0.0004031544 0.0008607337 6.341801e-05 0.0002389983\n",
       "7 -0.0444148565 0.0195765927 0.0484852322 1.374447e-03 0.0144317093\n",
       "8 -0.0367735469 0.0164391436 0.0403214453 1.254416e-03 0.0119526383\n",
       "  [,6]         [,7]         [,8]          [,9]          [,10]       \n",
       "1 0.0022094031 1.855860e-04 -0.0053538239  2.417218e-04 -0.016392872\n",
       "4 0.0002785484 2.252078e-05 -0.0007127678  1.914664e-05 -0.002234323\n",
       "5 0.0002386163 1.910769e-05 -0.0006185411  1.401738e-05 -0.001949295\n",
       "6 0.0002446797 1.830607e-05 -0.0006897356 -2.256756e-06 -0.002244884\n",
       "7 0.0162533313 1.321717e-03 -0.0412613771  1.215746e-03 -0.128915111\n",
       "8 0.0133914379 1.084446e-03 -0.0341918523  9.429830e-04 -0.107084095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(fit$generalized.weights[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for gwplot {neuralnet}\"><tr><td>gwplot {neuralnet}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Plot method for generalized weights</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>gwplot</code>, a method for objects of class <code>nn</code>, typically produced\n",
       "by <code>neuralnet</code>.  Plots the generalized weights (Intrator and Intrator,\n",
       "1993) for one specific covariate and one response variable.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "gwplot(x, rep = NULL, max = NULL, min = NULL, file = NULL,\n",
       "  selected.covariate = 1, selected.response = 1, highlight = FALSE,\n",
       "  type = \"p\", col = \"black\", ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>x</code></td>\n",
       "<td>\n",
       "<p>an object of class <code>nn</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>rep</code></td>\n",
       "<td>\n",
       "<p>an integer indicating the repetition to plot. If rep=&quot;best&quot;, the\n",
       "repetition with the smallest error will be plotted. If not stated all\n",
       "repetitions will be plotted.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>max</code></td>\n",
       "<td>\n",
       "<p>maximum of the y axis. In default, max is set to the highest\n",
       "y-value.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>min</code></td>\n",
       "<td>\n",
       "<p>minimum of the y axis. In default, min is set to the smallest\n",
       "y-value.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>file</code></td>\n",
       "<td>\n",
       "<p>a character string naming the plot to write to. If not stated,\n",
       "the plot will not be saved.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>selected.covariate</code></td>\n",
       "<td>\n",
       "<p>either a string of the covariate's name or an\n",
       "integer of the ordered covariates, indicating the reference covariate in the\n",
       "generalized weights plot. Defaulting to the first covariate.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>selected.response</code></td>\n",
       "<td>\n",
       "<p>either a string of the response variable's name or\n",
       "an integer of the ordered response variables, indicating the reference\n",
       "response in the generalized weights plot. Defaulting to the first response\n",
       "variable.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>highlight</code></td>\n",
       "<td>\n",
       "<p>a logical value, indicating whether to highlight (red\n",
       "color) the best repetition (smallest error). Only reasonable if rep=NULL.\n",
       "Default is FALSE</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>type</code></td>\n",
       "<td>\n",
       "<p>a character indicating the type of plotting; actually any of the\n",
       "types as in <code>plot.default</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>col</code></td>\n",
       "<td>\n",
       "<p>a color of the generalized weights.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Arguments to be passed to methods, such as graphical parameters\n",
       "(see <code>par</code>).</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Stefan Fritsch, Frauke Guenther <a href=\"mailto:guenther@leibniz-bips.de\">guenther@leibniz-bips.de</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Intrator O. and Intrator N. (1993) <em>Using Neural Nets for\n",
       "Interpretation of Nonlinear Models.</em> Proceedings of the Statistical\n",
       "Computing Section, 244-249 San Francisco: American Statistical Society\n",
       "(eds.)\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>neuralnet</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "\n",
       "data(infert, package=\"datasets\")\n",
       "print(net.infert &lt;- neuralnet(case~parity+induced+spontaneous, infert, \n",
       "\t\t                err.fct=\"ce\", linear.output=FALSE, likelihood=TRUE))\n",
       "gwplot(net.infert, selected.covariate=\"parity\")\n",
       "gwplot(net.infert, selected.covariate=\"induced\")\n",
       "gwplot(net.infert, selected.covariate=\"spontaneous\")\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>neuralnet</em> version 1.44.2 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{gwplot}{Plot method for generalized weights}{gwplot}\n",
       "\\keyword{neural}{gwplot}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{gwplot}, a method for objects of class \\code{nn}, typically produced\n",
       "by \\code{neuralnet}.  Plots the generalized weights (Intrator and Intrator,\n",
       "1993) for one specific covariate and one response variable.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "gwplot(x, rep = NULL, max = NULL, min = NULL, file = NULL,\n",
       "  selected.covariate = 1, selected.response = 1, highlight = FALSE,\n",
       "  type = \"p\", col = \"black\", ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{x}] an object of class \\code{nn}\n",
       "\n",
       "\\item[\\code{rep}] an integer indicating the repetition to plot. If rep=\"best\", the\n",
       "repetition with the smallest error will be plotted. If not stated all\n",
       "repetitions will be plotted.\n",
       "\n",
       "\\item[\\code{max}] maximum of the y axis. In default, max is set to the highest\n",
       "y-value.\n",
       "\n",
       "\\item[\\code{min}] minimum of the y axis. In default, min is set to the smallest\n",
       "y-value.\n",
       "\n",
       "\\item[\\code{file}] a character string naming the plot to write to. If not stated,\n",
       "the plot will not be saved.\n",
       "\n",
       "\\item[\\code{selected.covariate}] either a string of the covariate's name or an\n",
       "integer of the ordered covariates, indicating the reference covariate in the\n",
       "generalized weights plot. Defaulting to the first covariate.\n",
       "\n",
       "\\item[\\code{selected.response}] either a string of the response variable's name or\n",
       "an integer of the ordered response variables, indicating the reference\n",
       "response in the generalized weights plot. Defaulting to the first response\n",
       "variable.\n",
       "\n",
       "\\item[\\code{highlight}] a logical value, indicating whether to highlight (red\n",
       "color) the best repetition (smallest error). Only reasonable if rep=NULL.\n",
       "Default is FALSE\n",
       "\n",
       "\\item[\\code{type}] a character indicating the type of plotting; actually any of the\n",
       "types as in \\code{\\LinkA{plot.default}{plot.default}}.\n",
       "\n",
       "\\item[\\code{col}] a color of the generalized weights.\n",
       "\n",
       "\\item[\\code{...}] Arguments to be passed to methods, such as graphical parameters\n",
       "(see \\code{\\LinkA{par}{par}}).\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "Stefan Fritsch, Frauke Guenther \\email{guenther@leibniz-bips.de}\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Intrator O. and Intrator N. (1993) \\emph{Using Neural Nets for\n",
       "Interpretation of Nonlinear Models.} Proceedings of the Statistical\n",
       "Computing Section, 244-249 San Francisco: American Statistical Society\n",
       "(eds.)\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{neuralnet}{neuralnet}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "data(infert, package=\"datasets\")\n",
       "print(net.infert <- neuralnet(case~parity+induced+spontaneous, infert, \n",
       "\t\t                err.fct=\"ce\", linear.output=FALSE, likelihood=TRUE))\n",
       "gwplot(net.infert, selected.covariate=\"parity\")\n",
       "gwplot(net.infert, selected.covariate=\"induced\")\n",
       "gwplot(net.infert, selected.covariate=\"spontaneous\")\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "gwplot                package:neuralnet                R Documentation\n",
       "\n",
       "_\bP_\bl_\bo_\bt _\bm_\be_\bt_\bh_\bo_\bd _\bf_\bo_\br _\bg_\be_\bn_\be_\br_\ba_\bl_\bi_\bz_\be_\bd _\bw_\be_\bi_\bg_\bh_\bt_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     'gwplot', a method for objects of class 'nn', typically produced\n",
       "     by 'neuralnet'.  Plots the generalized weights (Intrator and\n",
       "     Intrator, 1993) for one specific covariate and one response\n",
       "     variable.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     gwplot(x, rep = NULL, max = NULL, min = NULL, file = NULL,\n",
       "       selected.covariate = 1, selected.response = 1, highlight = FALSE,\n",
       "       type = \"p\", col = \"black\", ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       x: an object of class 'nn'\n",
       "\n",
       "     rep: an integer indicating the repetition to plot. If rep=\"best\",\n",
       "          the repetition with the smallest error will be plotted. If\n",
       "          not stated all repetitions will be plotted.\n",
       "\n",
       "     max: maximum of the y axis. In default, max is set to the highest\n",
       "          y-value.\n",
       "\n",
       "     min: minimum of the y axis. In default, min is set to the smallest\n",
       "          y-value.\n",
       "\n",
       "    file: a character string naming the plot to write to. If not\n",
       "          stated, the plot will not be saved.\n",
       "\n",
       "selected.covariate: either a string of the covariate's name or an\n",
       "          integer of the ordered covariates, indicating the reference\n",
       "          covariate in the generalized weights plot. Defaulting to the\n",
       "          first covariate.\n",
       "\n",
       "selected.response: either a string of the response variable's name or\n",
       "          an integer of the ordered response variables, indicating the\n",
       "          reference response in the generalized weights plot.\n",
       "          Defaulting to the first response variable.\n",
       "\n",
       "highlight: a logical value, indicating whether to highlight (red color)\n",
       "          the best repetition (smallest error). Only reasonable if\n",
       "          rep=NULL. Default is FALSE\n",
       "\n",
       "    type: a character indicating the type of plotting; actually any of\n",
       "          the types as in 'plot.default'.\n",
       "\n",
       "     col: a color of the generalized weights.\n",
       "\n",
       "     ...: Arguments to be passed to methods, such as graphical\n",
       "          parameters (see 'par').\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Stefan Fritsch, Frauke Guenther <email: guenther@leibniz-bips.de>\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Intrator O. and Intrator N. (1993) _Using Neural Nets for\n",
       "     Interpretation of Nonlinear Models._ Proceedings of the\n",
       "     Statistical Computing Section, 244-249 San Francisco: American\n",
       "     Statistical Society (eds.)\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     'neuralnet'\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     data(infert, package=\"datasets\")\n",
       "     print(net.infert <- neuralnet(case~parity+induced+spontaneous, infert, \n",
       "                                     err.fct=\"ce\", linear.output=FALSE, likelihood=TRUE))\n",
       "     gwplot(net.infert, selected.covariate=\"parity\")\n",
       "     gwplot(net.infert, selected.covariate=\"induced\")\n",
       "     gwplot(net.infert, selected.covariate=\"spontaneous\")\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?gwplot   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "Plot with title \"Response: use\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "par(mfrow=c(1,2))\n",
    "gwplot(fit, selected.covariate = \"vis.yes\")   #neuralnet\n",
    "gwplot(fit, selected.covariate = \"wind.tail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsTrain <- compute(fit, train[, 1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         \n",
       "predTrain   0   1\n",
       "        0  73   0\n",
       "        1   0 107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predTrain <- resultsTrain$net.result\n",
    "predTrain <- ifelse(predTrain >= 0.5, 1, 0)\n",
    "table(predTrain, train$use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "predTest  0  1\n",
       "       0 38  2\n",
       "       1  0 36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultsTest <- compute(fit, test[,1:10])\n",
    "predTest <- resultsTest$net.result\n",
    "predTest <- ifelse(predTest >= 0.5, 1, 0)\n",
    "table(predTest, test$use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>58</li>\n",
       "\t<li>59</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 58\n",
       "\\item 59\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 58\n",
       "2. 59\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 58 59"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which(predTest ==0 & test$use ==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>stability.xstab</th><th scope=col>error.MM</th><th scope=col>error.SS</th><th scope=col>error.XL</th><th scope=col>sign.pp</th><th scope=col>wind.tail</th><th scope=col>magn.Medium</th><th scope=col>magn.Out</th><th scope=col>magn.Strong</th><th scope=col>vis.yes</th><th scope=col>use</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>201</th><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & stability.xstab & error.MM & error.SS & error.XL & sign.pp & wind.tail & magn.Medium & magn.Out & magn.Strong & vis.yes & use\\\\\n",
       "\\hline\n",
       "\t201 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | stability.xstab | error.MM | error.SS | error.XL | sign.pp | wind.tail | magn.Medium | magn.Out | magn.Strong | vis.yes | use |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 201 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "    stability.xstab error.MM error.SS error.XL sign.pp wind.tail magn.Medium\n",
       "201 0               1        0        0        1       0         0          \n",
       "    magn.Out magn.Strong vis.yes use\n",
       "201 0        0           1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test[58,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which(predTest == 1 & shuttleTest$use == 0)\n",
    "shuttleTest[62,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\"package:h2o\" %in% search()) { detach(\"package:h2o\", unload=TRUE) }\n",
    "if (\"h2o\" %in% rownames(installed.packages())) { remove.packages(\"h2o\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'statmod' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\alsdu\\AppData\\Local\\Temp\\Rtmpc5M5zu\\downloaded_packages\n",
      "\n",
      "  There is a binary version available but the source version is later:\n",
      "        binary   source needs_compilation\n",
      "RCurl 1.98-1.3 1.98-1.4              TRUE\n",
      "\n",
      "  Binaries will be installed\n",
      "package 'RCurl' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\alsdu\\AppData\\Local\\Temp\\Rtmpc5M5zu\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# Next, we download packages that H2O depends on.\n",
    "if (! (\"methods\" %in% rownames(installed.packages()))) { install.packages(\"methods\") }\n",
    "if (! (\"statmod\" %in% rownames(installed.packages()))) { install.packages(\"statmod\") }\n",
    "if (! (\"stats\" %in% rownames(installed.packages()))) { install.packages(\"stats\") }\n",
    "if (! (\"graphics\" %in% rownames(installed.packages()))) { install.packages(\"graphics\") }\n",
    "if (! (\"RCurl\" %in% rownames(installed.packages()))) { install.packages(\"RCurl\") }\n",
    "if (! (\"jsonlite\" %in% rownames(installed.packages()))) { install.packages(\"jsonlite\") }\n",
    "if (! (\"tools\" %in% rownames(installed.packages()))) { install.packages(\"tools\") }\n",
    "if (! (\"utils\" %in% rownames(installed.packages()))) { install.packages(\"utils\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your next step is to start H2O:\n",
      "    > h2o.init()\n",
      "\n",
      "For H2O package documentation, ask for help:\n",
      "    > ??h2o\n",
      "\n",
      "After starting H2O, you can use the Web UI at http://localhost:54321\n",
      "For more information visit http://docs.h2o.ai\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Attaching package: 'h2o'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cor, sd, var\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n",
      "    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n",
      "    log10, log1p, log2, round, signif, trunc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"h2o\", type=\"source\", repos=(c(\"http://h2o-release.s3.amazonaws.com/h2o/rel-tverberg/5/R\")))\n",
    "library(h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"C:/Users/alsdu/Downloads/MasteringMachineLearningwithRSecondEdition_Code/MasteringMachineLearningwithRSecondEdition_Code/data-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir<-getwd()\n",
    "path<-paste0(mydir, \"/bank_DL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "<simpleError in system2(command, \"-version\", stdout = TRUE, stderr = TRUE): '\"\"' not found>\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in value[[3L]](cond): You have a 32-bit version of Java. H2O works best with 64-bit Java.\nPlease download the latest Java SE JDK 7 from the following URL:\nhttp://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html\n",
     "output_type": "error",
     "traceback": [
      "Error in value[[3L]](cond): You have a 32-bit version of Java. H2O works best with 64-bit Java.\nPlease download the latest Java SE JDK 7 from the following URL:\nhttp://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html\nTraceback:\n",
      "1. h2o.init(nthreads = -1)",
      "2. .h2o.startJar(ip = ip, port = port, nthreads = nthreads, max_memory = max_mem_size, \n .     min_memory = min_mem_size, enable_assertions = enable_assertions, \n .     forceDL = forceDL, license = license, ice_root = ice_root, \n .     stdout = stdout)",
      "3. tryCatch({\n .     system2(command, \"-version\", stdout = TRUE, stderr = TRUE)\n . }, error = function(err) {\n .     print(err)\n .     stop(\"You have a 32-bit version of Java. H2O works best with 64-bit Java.\\n\", \n .         \"Please download the latest Java SE JDK 7 from the following URL:\\n\", \n .         \"http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html\")\n . })",
      "4. tryCatchList(expr, classes, parentenv, handlers)",
      "5. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "6. value[[3L]](cond)",
      "7. stop(\"You have a 32-bit version of Java. H2O works best with 64-bit Java.\\n\", \n .     \"Please download the latest Java SE JDK 7 from the following URL:\\n\", \n .     \"http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html\")"
     ]
    }
   ],
   "source": [
    "localLH20=h2o.init(nthreads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in h2o.getConnection(): No active connection to an H2O cluster. Did you run `h2o.init()` ?\n",
     "output_type": "error",
     "traceback": [
      "Error in h2o.getConnection(): No active connection to an H2O cluster. Did you run `h2o.init()` ?\nTraceback:\n",
      "1. h2o.uploadFile(path = path)",
      "2. .key.make(path)",
      "3. h2o.getConnection()",
      "4. stop(\"No active connection to an H2O cluster. Did you run `h2o.init()` ?\")"
     ]
    }
   ],
   "source": [
    "bank <- h2o.uploadFile(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class(bank)\n",
    "str(bank)\n",
    "head(bank)\n",
    "summary(bank)\n",
    "h2o.table(bank$y)\n",
    "\n",
    "rand <- h2o.runif(bank, seed = 123)\n",
    "\n",
    "train <- bank[rand <= 0.7, ]\n",
    "train <- h2o.assign(train, key = \"train\")\n",
    "test <- bank[rand  > 0.7, ]\n",
    "test <- h2o.assign(test, key = \"test\")\n",
    "\n",
    "h2o.table(train[, 64])\n",
    "h2o.table(test[, 64])\n",
    "\n",
    "hyper_params <- list(\n",
    "  activation = c(\"Tanh\", \"TanhWithDropout\"),\n",
    "  hidden = list(c(20,20),c(40, 40),c(30, 30, 30)),\n",
    "  input_dropout_ratio = c(0, 0.05),\n",
    "  rate = c(0.01, 0.25)\n",
    ")\n",
    "\n",
    "search_criteria = list(\n",
    "  strategy = \"RandomDiscrete\", max_runtime_secs = 420,     \n",
    "  max_models = 100, seed = 123, stopping_rounds = 5, \n",
    "  stopping_tolerance = 0.01\n",
    ")\n",
    "\n",
    "randomSearch <- h2o.grid(\n",
    "  algorithm = \"deeplearning\",\n",
    "  grid_id = \"randomSearch\",\n",
    "  training_frame = train,\n",
    "  validation_frame = test, \n",
    "  x = 1:63, \n",
    "  y = 64,\n",
    "  epochs = 1,\n",
    "  stopping_metric = \"misclassification\",\n",
    "  hyper_params = hyper_params,\n",
    "  search_criteria = search_criteria\n",
    ")                        \n",
    "\n",
    "grid <- h2o.getGrid(\"randomSearch\", sort_by = \"auc\", decreasing = T)\n",
    "grid\n",
    "\n",
    "best_model <- h2o.getModel(grid@model_ids[[1]])\n",
    "h2o.confusionMatrix(best_model, valid = T)\n",
    "\n",
    "dlmodel <- h2o.deeplearning(\n",
    "  x = 1:63,\n",
    "  y = 64, \n",
    "  training_frame = train,\n",
    "  validation_frame = \n",
    "  hidden = c(30, 30, 30),\n",
    "  epochs = 3,\n",
    "  nfolds = 5,\n",
    "  fold_assignment=\"Stratified\",\n",
    "  balance_classes = T,\n",
    "  activation = \"TanhWithDropout\",\n",
    "  seed = 123,\n",
    "  adaptive_rate = F, \n",
    "  input_dropout_ratio = 0.05,\n",
    "  stopping_metric = \"misclassification\",\n",
    "  variable_importances = T\n",
    ")\n",
    "\n",
    "dlmodel\n",
    "\n",
    "perf <- h2o.performance(dlmodel, test)\n",
    "perf\n",
    "\n",
    "dlmodel@model$variable_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. k최근접 이웃과 서포트벡터머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)  #SVM\n",
    "library(kernlab) #SVM피처 선택에 도움   ksvm \n",
    "library(pROC) # SVM 피처 선택에 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'class' is in use and will not be installed\"also installing the dependency 'igraph'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'igraph' successfully unpacked and MD5 sums checked\n",
      "package 'kknn' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\alsdu\\AppData\\Local\\Temp\\Rtmpc5M5zu\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MASS' is in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'reshape2' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"cannot remove prior installation of package 'reshape2'\"Warning message in file.copy(savedcopy, lib, recursive = TRUE):\n",
      "\"C:\\Users\\alsdu\\anaconda3\\Lib\\R\\library\\00LOCK\\reshape2\\libs\\x64\\reshape2.dll를 C:\\Users\\alsdu\\anaconda3\\Lib\\R\\library\\reshape2\\libs\\x64\\reshape2.dll로 복사하는데 문제가 발생했습니다: Permission denied\"Warning message:\n",
      "\"restored 'reshape2'\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\alsdu\\AppData\\Local\\Temp\\Rtmpc5M5zu\\downloaded_packages\n",
      "\n",
      "  There is a binary version available but the source version is later:\n",
      "        binary source needs_compilation\n",
      "ggplot2  3.3.3  3.3.5             FALSE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "installing the source package 'ggplot2'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"class\")   ;  install.packages(\"kknn\")  ; install.packages(\"reshape2\") ; install.packages(\"ggplot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MASS' is in use and will not be installed\""
     ]
    }
   ],
   "source": [
    "install.packages(\"MASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'kknn' was built under R version 3.6.3\"\n",
      "Attaching package: 'kknn'\n",
      "\n",
      "The following object is masked from 'package:caret':\n",
      "\n",
      "    contr.dummy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(class)  #k-근접이웃법\n",
    "library(kknn)   #가중 k-근접이웃법\n",
    "library(caret) #인자 조정 선별\n",
    "library(MASS) #데이터 담고 있는 라이브러라\n",
    "library(reshape2) #박스플롯을 생성하는데 도움\n",
    "library(ggplot2) # 박스플롯 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t200 obs. of  8 variables:\n",
      " $ npreg: int  5 7 5 0 0 5 3 1 3 2 ...\n",
      " $ glu  : int  86 195 77 165 107 97 83 193 142 128 ...\n",
      " $ bp   : int  68 70 82 76 60 76 58 50 80 78 ...\n",
      " $ skin : int  28 33 41 43 25 27 31 16 15 37 ...\n",
      " $ bmi  : num  30.2 25.1 35.8 47.9 26.4 35.6 34.3 25.9 32.4 43.3 ...\n",
      " $ ped  : num  0.364 0.163 0.156 0.259 0.133 ...\n",
      " $ age  : int  24 55 35 26 23 52 25 24 63 31 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 1 1 2 ...\n",
      "'data.frame':\t332 obs. of  8 variables:\n",
      " $ npreg: int  6 1 1 3 2 5 0 1 3 9 ...\n",
      " $ glu  : int  148 85 89 78 197 166 118 103 126 119 ...\n",
      " $ bp   : int  72 66 66 50 70 72 84 30 88 80 ...\n",
      " $ skin : int  35 29 23 32 45 19 47 38 41 35 ...\n",
      " $ bmi  : num  33.6 26.6 28.1 31 30.5 25.8 45.8 43.3 39.3 29 ...\n",
      " $ ped  : num  0.627 0.351 0.167 0.248 0.158 0.587 0.551 0.183 0.704 0.263 ...\n",
      " $ age  : int  50 31 21 26 53 51 31 33 27 29 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 2 2 2 2 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "data(Pima.tr); str(Pima.tr)\n",
    "data(Pima.te); str(Pima.te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t532 obs. of  8 variables:\n",
      " $ npreg: int  5 7 5 0 0 5 3 1 3 2 ...\n",
      " $ glu  : int  86 195 77 165 107 97 83 193 142 128 ...\n",
      " $ bp   : int  68 70 82 76 60 76 58 50 80 78 ...\n",
      " $ skin : int  28 33 41 43 25 27 31 16 15 37 ...\n",
      " $ bmi  : num  30.2 25.1 35.8 47.9 26.4 35.6 34.3 25.9 32.4 43.3 ...\n",
      " $ ped  : num  0.364 0.163 0.156 0.259 0.133 ...\n",
      " $ age  : int  24 55 35 26 23 52 25 24 63 31 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "pima<-rbind(Pima.tr, Pima.te)\n",
    "str(pima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>type</th><th scope=col>variable</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 5   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 7   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 5   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 0   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 0   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 5   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 3   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 3   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 2   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 0   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 9   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td>12   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 4   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td>11   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 0   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 2   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 4   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 0   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 9   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 1   </td></tr>\n",
       "\t<tr><td>Yes  </td><td>npreg</td><td> 0   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 5   </td></tr>\n",
       "\t<tr><td>No   </td><td>npreg</td><td> 2   </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>38 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>21 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>34 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>31 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>56 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>24 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>42 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>25 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>22 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>24 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>22 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>21 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>42 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>21 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>48 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>26 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>22 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>39 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>46 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>27 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>36 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>28 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>25 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>26 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>37 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>22 </td></tr>\n",
       "\t<tr><td>Yes</td><td>age</td><td>43 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>63 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>30 </td></tr>\n",
       "\t<tr><td>No </td><td>age</td><td>23 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " type & variable & value\\\\\n",
       "\\hline\n",
       "\t No    & npreg &  5   \\\\\n",
       "\t Yes   & npreg &  7   \\\\\n",
       "\t No    & npreg &  5   \\\\\n",
       "\t No    & npreg &  0   \\\\\n",
       "\t No    & npreg &  0   \\\\\n",
       "\t Yes   & npreg &  5   \\\\\n",
       "\t No    & npreg &  3   \\\\\n",
       "\t No    & npreg &  1   \\\\\n",
       "\t No    & npreg &  3   \\\\\n",
       "\t Yes   & npreg &  2   \\\\\n",
       "\t Yes   & npreg &  0   \\\\\n",
       "\t No    & npreg &  9   \\\\\n",
       "\t Yes   & npreg &  1   \\\\\n",
       "\t Yes   & npreg & 12   \\\\\n",
       "\t No    & npreg &  1   \\\\\n",
       "\t No    & npreg &  4   \\\\\n",
       "\t No    & npreg &  1   \\\\\n",
       "\t Yes   & npreg & 11   \\\\\n",
       "\t Yes   & npreg &  1   \\\\\n",
       "\t No    & npreg &  0   \\\\\n",
       "\t No    & npreg &  2   \\\\\n",
       "\t No    & npreg &  1   \\\\\n",
       "\t No    & npreg &  4   \\\\\n",
       "\t No    & npreg &  0   \\\\\n",
       "\t No    & npreg &  1   \\\\\n",
       "\t Yes   & npreg &  9   \\\\\n",
       "\t No    & npreg &  1   \\\\\n",
       "\t Yes   & npreg &  0   \\\\\n",
       "\t No    & npreg &  5   \\\\\n",
       "\t No    & npreg &  2   \\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t Yes & age & 38 \\\\\n",
       "\t No  & age & 21 \\\\\n",
       "\t Yes & age & 34 \\\\\n",
       "\t Yes & age & 31 \\\\\n",
       "\t No  & age & 56 \\\\\n",
       "\t No  & age & 24 \\\\\n",
       "\t No  & age & 42 \\\\\n",
       "\t No  & age & 25 \\\\\n",
       "\t No  & age & 22 \\\\\n",
       "\t Yes & age & 24 \\\\\n",
       "\t No  & age & 22 \\\\\n",
       "\t No  & age & 21 \\\\\n",
       "\t No  & age & 42 \\\\\n",
       "\t No  & age & 21 \\\\\n",
       "\t Yes & age & 48 \\\\\n",
       "\t No  & age & 26 \\\\\n",
       "\t No  & age & 22 \\\\\n",
       "\t No  & age & 39 \\\\\n",
       "\t No  & age & 46 \\\\\n",
       "\t Yes & age & 27 \\\\\n",
       "\t Yes & age & 36 \\\\\n",
       "\t No  & age & 28 \\\\\n",
       "\t No  & age & 25 \\\\\n",
       "\t Yes & age & 26 \\\\\n",
       "\t Yes & age & 37 \\\\\n",
       "\t No  & age & 22 \\\\\n",
       "\t Yes & age & 43 \\\\\n",
       "\t No  & age & 63 \\\\\n",
       "\t No  & age & 30 \\\\\n",
       "\t No  & age & 23 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| type | variable | value |\n",
       "|---|---|---|\n",
       "| No    | npreg |  5    |\n",
       "| Yes   | npreg |  7    |\n",
       "| No    | npreg |  5    |\n",
       "| No    | npreg |  0    |\n",
       "| No    | npreg |  0    |\n",
       "| Yes   | npreg |  5    |\n",
       "| No    | npreg |  3    |\n",
       "| No    | npreg |  1    |\n",
       "| No    | npreg |  3    |\n",
       "| Yes   | npreg |  2    |\n",
       "| Yes   | npreg |  0    |\n",
       "| No    | npreg |  9    |\n",
       "| Yes   | npreg |  1    |\n",
       "| Yes   | npreg | 12    |\n",
       "| No    | npreg |  1    |\n",
       "| No    | npreg |  4    |\n",
       "| No    | npreg |  1    |\n",
       "| Yes   | npreg | 11    |\n",
       "| Yes   | npreg |  1    |\n",
       "| No    | npreg |  0    |\n",
       "| No    | npreg |  2    |\n",
       "| No    | npreg |  1    |\n",
       "| No    | npreg |  4    |\n",
       "| No    | npreg |  0    |\n",
       "| No    | npreg |  1    |\n",
       "| Yes   | npreg |  9    |\n",
       "| No    | npreg |  1    |\n",
       "| Yes   | npreg |  0    |\n",
       "| No    | npreg |  5    |\n",
       "| No    | npreg |  2    |\n",
       "| ... | ... | ... |\n",
       "| Yes | age | 38  |\n",
       "| No  | age | 21  |\n",
       "| Yes | age | 34  |\n",
       "| Yes | age | 31  |\n",
       "| No  | age | 56  |\n",
       "| No  | age | 24  |\n",
       "| No  | age | 42  |\n",
       "| No  | age | 25  |\n",
       "| No  | age | 22  |\n",
       "| Yes | age | 24  |\n",
       "| No  | age | 22  |\n",
       "| No  | age | 21  |\n",
       "| No  | age | 42  |\n",
       "| No  | age | 21  |\n",
       "| Yes | age | 48  |\n",
       "| No  | age | 26  |\n",
       "| No  | age | 22  |\n",
       "| No  | age | 39  |\n",
       "| No  | age | 46  |\n",
       "| Yes | age | 27  |\n",
       "| Yes | age | 36  |\n",
       "| No  | age | 28  |\n",
       "| No  | age | 25  |\n",
       "| Yes | age | 26  |\n",
       "| Yes | age | 37  |\n",
       "| No  | age | 22  |\n",
       "| Yes | age | 43  |\n",
       "| No  | age | 63  |\n",
       "| No  | age | 30  |\n",
       "| No  | age | 23  |\n",
       "\n"
      ],
      "text/plain": [
       "     type variable value\n",
       "1    No   npreg     5   \n",
       "2    Yes  npreg     7   \n",
       "3    No   npreg     5   \n",
       "4    No   npreg     0   \n",
       "5    No   npreg     0   \n",
       "6    Yes  npreg     5   \n",
       "7    No   npreg     3   \n",
       "8    No   npreg     1   \n",
       "9    No   npreg     3   \n",
       "10   Yes  npreg     2   \n",
       "11   Yes  npreg     0   \n",
       "12   No   npreg     9   \n",
       "13   Yes  npreg     1   \n",
       "14   Yes  npreg    12   \n",
       "15   No   npreg     1   \n",
       "16   No   npreg     4   \n",
       "17   No   npreg     1   \n",
       "18   Yes  npreg    11   \n",
       "19   Yes  npreg     1   \n",
       "20   No   npreg     0   \n",
       "21   No   npreg     2   \n",
       "22   No   npreg     1   \n",
       "23   No   npreg     4   \n",
       "24   No   npreg     0   \n",
       "25   No   npreg     1   \n",
       "26   Yes  npreg     9   \n",
       "27   No   npreg     1   \n",
       "28   Yes  npreg     0   \n",
       "29   No   npreg     5   \n",
       "30   No   npreg     2   \n",
       "...  ...  ...      ...  \n",
       "3695 Yes  age      38   \n",
       "3696 No   age      21   \n",
       "3697 Yes  age      34   \n",
       "3698 Yes  age      31   \n",
       "3699 No   age      56   \n",
       "3700 No   age      24   \n",
       "3701 No   age      42   \n",
       "3702 No   age      25   \n",
       "3703 No   age      22   \n",
       "3704 Yes  age      24   \n",
       "3705 No   age      22   \n",
       "3706 No   age      21   \n",
       "3707 No   age      42   \n",
       "3708 No   age      21   \n",
       "3709 Yes  age      48   \n",
       "3710 No   age      26   \n",
       "3711 No   age      22   \n",
       "3712 No   age      39   \n",
       "3713 No   age      46   \n",
       "3714 Yes  age      27   \n",
       "3715 Yes  age      36   \n",
       "3716 No   age      28   \n",
       "3717 No   age      25   \n",
       "3718 Yes  age      26   \n",
       "3719 Yes  age      37   \n",
       "3720 No   age      22   \n",
       "3721 Yes  age      43   \n",
       "3722 No   age      63   \n",
       "3723 No   age      30   \n",
       "3724 No   age      23   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pima.melt<-melt(pima, id.var=\"type\")\n",
    "pima.melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAaGhozMzNNTU1o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\niwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot (pima.melt, aes(x=type, y=value))+\n",
    "geom_boxplot()+ facet_wrap(~variable, ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t532 obs. of  7 variables:\n",
      " $ npreg: num  0.448 1.052 0.448 -1.062 -1.062 ...\n",
      " $ glu  : num  -1.13 2.386 -1.42 1.418 -0.453 ...\n",
      " $ bp   : num  -0.285 -0.122 0.852 0.365 -0.935 ...\n",
      " $ skin : num  -0.112 0.363 1.123 1.313 -0.397 ...\n",
      " $ bmi  : num  -0.391 -1.132 0.423 2.181 -0.943 ...\n",
      " $ ped  : num  -0.403 -0.987 -1.007 -0.708 -1.074 ...\n",
      " $ age  : num  -0.708 2.173 0.315 -0.522 -0.801 ...\n"
     ]
    }
   ],
   "source": [
    "pima.scale<-data.frame(scale(pima[,-8]))  ; str(pima.scale)  # target 빼고 스케일링 함   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 1 1 2 1 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "pima.scale$type <- pima$type\n",
    "str(pima$type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAaGhozMzNNTU1o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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pima.scale.melt<- melt(pima.scale, id.var=\"type\")\n",
    "ggplot(data=pima.scale.melt, aes(x=type, y=value))+ geom_boxplot() + facet_wrap(~variable, ncol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>npreg</th><th scope=col>glu</th><th scope=col>bp</th><th scope=col>skin</th><th scope=col>bmi</th><th scope=col>ped</th><th scope=col>age</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>npreg</th><td>1.000000000</td><td>0.1253296  </td><td>0.204663421</td><td>0.09508511 </td><td>0.008576282</td><td>0.007435104</td><td>0.64074687 </td></tr>\n",
       "\t<tr><th scope=row>glu</th><td>0.125329647</td><td>1.0000000  </td><td>0.219177950</td><td>0.22659042 </td><td>0.247079294</td><td>0.165817411</td><td>0.27890711 </td></tr>\n",
       "\t<tr><th scope=row>bp</th><td>0.204663421</td><td>0.2191779  </td><td>1.000000000</td><td>0.22607244 </td><td>0.307356904</td><td>0.008047249</td><td>0.34693872 </td></tr>\n",
       "\t<tr><th scope=row>skin</th><td>0.095085114</td><td>0.2265904  </td><td>0.226072440</td><td>1.00000000 </td><td>0.647422386</td><td>0.118635569</td><td>0.16133614 </td></tr>\n",
       "\t<tr><th scope=row>bmi</th><td>0.008576282</td><td>0.2470793  </td><td>0.307356904</td><td>0.64742239 </td><td>1.000000000</td><td>0.151107136</td><td>0.07343826 </td></tr>\n",
       "\t<tr><th scope=row>ped</th><td>0.007435104</td><td>0.1658174  </td><td>0.008047249</td><td>0.11863557 </td><td>0.151107136</td><td>1.000000000</td><td>0.07165413 </td></tr>\n",
       "\t<tr><th scope=row>age</th><td>0.640746866</td><td>0.2789071  </td><td>0.346938723</td><td>0.16133614 </td><td>0.073438257</td><td>0.071654133</td><td>1.00000000 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       "  & npreg & glu & bp & skin & bmi & ped & age\\\\\n",
       "\\hline\n",
       "\tnpreg & 1.000000000 & 0.1253296   & 0.204663421 & 0.09508511  & 0.008576282 & 0.007435104 & 0.64074687 \\\\\n",
       "\tglu & 0.125329647 & 1.0000000   & 0.219177950 & 0.22659042  & 0.247079294 & 0.165817411 & 0.27890711 \\\\\n",
       "\tbp & 0.204663421 & 0.2191779   & 1.000000000 & 0.22607244  & 0.307356904 & 0.008047249 & 0.34693872 \\\\\n",
       "\tskin & 0.095085114 & 0.2265904   & 0.226072440 & 1.00000000  & 0.647422386 & 0.118635569 & 0.16133614 \\\\\n",
       "\tbmi & 0.008576282 & 0.2470793   & 0.307356904 & 0.64742239  & 1.000000000 & 0.151107136 & 0.07343826 \\\\\n",
       "\tped & 0.007435104 & 0.1658174   & 0.008047249 & 0.11863557  & 0.151107136 & 1.000000000 & 0.07165413 \\\\\n",
       "\tage & 0.640746866 & 0.2789071   & 0.346938723 & 0.16133614  & 0.073438257 & 0.071654133 & 1.00000000 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | npreg | glu | bp | skin | bmi | ped | age |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| npreg | 1.000000000 | 0.1253296   | 0.204663421 | 0.09508511  | 0.008576282 | 0.007435104 | 0.64074687  |\n",
       "| glu | 0.125329647 | 1.0000000   | 0.219177950 | 0.22659042  | 0.247079294 | 0.165817411 | 0.27890711  |\n",
       "| bp | 0.204663421 | 0.2191779   | 1.000000000 | 0.22607244  | 0.307356904 | 0.008047249 | 0.34693872  |\n",
       "| skin | 0.095085114 | 0.2265904   | 0.226072440 | 1.00000000  | 0.647422386 | 0.118635569 | 0.16133614  |\n",
       "| bmi | 0.008576282 | 0.2470793   | 0.307356904 | 0.64742239  | 1.000000000 | 0.151107136 | 0.07343826  |\n",
       "| ped | 0.007435104 | 0.1658174   | 0.008047249 | 0.11863557  | 0.151107136 | 1.000000000 | 0.07165413  |\n",
       "| age | 0.640746866 | 0.2789071   | 0.346938723 | 0.16133614  | 0.073438257 | 0.071654133 | 1.00000000  |\n",
       "\n"
      ],
      "text/plain": [
       "      npreg       glu       bp          skin       bmi         ped        \n",
       "npreg 1.000000000 0.1253296 0.204663421 0.09508511 0.008576282 0.007435104\n",
       "glu   0.125329647 1.0000000 0.219177950 0.22659042 0.247079294 0.165817411\n",
       "bp    0.204663421 0.2191779 1.000000000 0.22607244 0.307356904 0.008047249\n",
       "skin  0.095085114 0.2265904 0.226072440 1.00000000 0.647422386 0.118635569\n",
       "bmi   0.008576282 0.2470793 0.307356904 0.64742239 1.000000000 0.151107136\n",
       "ped   0.007435104 0.1658174 0.008047249 0.11863557 0.151107136 1.000000000\n",
       "age   0.640746866 0.2789071 0.346938723 0.16133614 0.073438257 0.071654133\n",
       "      age       \n",
       "npreg 0.64074687\n",
       "glu   0.27890711\n",
       "bp    0.34693872\n",
       "skin  0.16133614\n",
       "bmi   0.07343826\n",
       "ped   0.07165413\n",
       "age   1.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor(pima.scale[-8])   #파라미터가 제대로 조정됨->문제가 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " No Yes \n",
       "355 177 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(pima.scale$type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind<-sample(1:nrow(pima.scale), nrow(pima.scale)*0.7, replace=FALSE)\n",
    "train<-pima.scale[ind,]\n",
    "test<-pima.scale[-ind,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t372 obs. of  8 variables:\n",
      " $ npreg: num  1.05 -0.76 0.75 -0.76 -0.76 ...\n",
      " $ glu  : num  1.87 -0.775 -1.324 0.225 -1.098 ...\n",
      " $ bp   : num  1.909 -0.285 -0.447 -1.909 0.528 ...\n",
      " $ skin : num  0.1727 -0.7775 0.0777 1.503 -0.2074 ...\n",
      " $ bmi  : num  0.19 -0.827 -0.972 1.106 0.248 ...\n",
      " $ ped  : num  -0.984 1.718 -0.551 0.319 -1.167 ...\n",
      " $ age  : num  2.638 -0.893 0.872 -0.708 -0.893 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 1 1 1 ...\n",
      "'data.frame':\t160 obs. of  8 variables:\n",
      " $ npreg: num  -1.062 -0.76 0.146 2.259 -1.062 ...\n",
      " $ glu  : num  -0.453 -1.13 -0.711 0.709 0.58 ...\n",
      " $ bp   : num  -0.935 -0.447 0.365 1.827 -0.772 ...\n",
      " $ skin : num  -0.397 2.168 -1.348 0.363 -1.158 ...\n",
      " $ bmi  : num  -0.943 1.222 -1.408 0.539 -1.568 ...\n",
      " $ ped  : num  -1.074 1.202 -0.813 -0.723 -0.859 ...\n",
      " $ age  : num  -0.801 -0.243 -0.986 1.801 -0.986 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 2 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(train); str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t375 obs. of  8 variables:\n",
      " $ npreg: num  1.052 0.448 -1.062 -1.062 0.448 ...\n",
      " $ glu  : num  2.386 -1.42 1.418 -0.453 -0.775 ...\n",
      " $ bp   : num  -0.122 0.852 0.365 -0.935 0.365 ...\n",
      " $ skin : num  0.363 1.123 1.313 -0.397 -0.207 ...\n",
      " $ bmi  : num  -1.132 0.423 2.181 -0.943 0.394 ...\n",
      " $ ped  : num  -0.987 -1.007 -0.708 -1.074 -0.363 ...\n",
      " $ age  : num  2.173 0.315 -0.522 -0.801 1.894 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 2 1 1 2 2 1 ...\n",
      "'data.frame':\t157 obs. of  8 variables:\n",
      " $ npreg: num  0.448 -0.156 -0.76 2.561 2.259 ...\n",
      " $ glu  : num  -1.13 0.676 2.193 -0.936 0.709 ...\n",
      " $ bp   : num  -0.285 0.69 -0.935 -0.772 1.827 ...\n",
      " $ skin : num  -0.112 -1.348 -0.587 -2.108 0.363 ...\n",
      " $ bmi  : num  -0.391 -0.0712 -0.4055 -0.7688 0.5391 ...\n",
      " $ ped  : num  -0.403 -0.879 -0.305 1.228 -0.723 ...\n",
      " $ age  : num  -0.708 2.916 2.545 1.151 1.801 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 1 1 2 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "idx<-sample(2, nrow(pima.scale), replace=TRUE, prob=c(0.7, 0.3))\n",
    "train2<-pima.scale[idx==1,]\n",
    "test2<-pima.scale[idx==2, ]\n",
    "str(train2) ; str(test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>.k</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 2</td></tr>\n",
       "\t<tr><td> 3</td></tr>\n",
       "\t<tr><td> 4</td></tr>\n",
       "\t<tr><td> 5</td></tr>\n",
       "\t<tr><td> 6</td></tr>\n",
       "\t<tr><td> 7</td></tr>\n",
       "\t<tr><td> 8</td></tr>\n",
       "\t<tr><td> 9</td></tr>\n",
       "\t<tr><td>10</td></tr>\n",
       "\t<tr><td>11</td></tr>\n",
       "\t<tr><td>12</td></tr>\n",
       "\t<tr><td>13</td></tr>\n",
       "\t<tr><td>14</td></tr>\n",
       "\t<tr><td>15</td></tr>\n",
       "\t<tr><td>16</td></tr>\n",
       "\t<tr><td>17</td></tr>\n",
       "\t<tr><td>18</td></tr>\n",
       "\t<tr><td>19</td></tr>\n",
       "\t<tr><td>20</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " .k\\\\\n",
       "\\hline\n",
       "\t  2\\\\\n",
       "\t  3\\\\\n",
       "\t  4\\\\\n",
       "\t  5\\\\\n",
       "\t  6\\\\\n",
       "\t  7\\\\\n",
       "\t  8\\\\\n",
       "\t  9\\\\\n",
       "\t 10\\\\\n",
       "\t 11\\\\\n",
       "\t 12\\\\\n",
       "\t 13\\\\\n",
       "\t 14\\\\\n",
       "\t 15\\\\\n",
       "\t 16\\\\\n",
       "\t 17\\\\\n",
       "\t 18\\\\\n",
       "\t 19\\\\\n",
       "\t 20\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| .k |\n",
       "|---|\n",
       "|  2 |\n",
       "|  3 |\n",
       "|  4 |\n",
       "|  5 |\n",
       "|  6 |\n",
       "|  7 |\n",
       "|  8 |\n",
       "|  9 |\n",
       "| 10 |\n",
       "| 11 |\n",
       "| 12 |\n",
       "| 13 |\n",
       "| 14 |\n",
       "| 15 |\n",
       "| 16 |\n",
       "| 17 |\n",
       "| 18 |\n",
       "| 19 |\n",
       "| 20 |\n",
       "\n"
      ],
      "text/plain": [
       "   .k\n",
       "1   2\n",
       "2   3\n",
       "3   4\n",
       "4   5\n",
       "5   6\n",
       "6   7\n",
       "7   8\n",
       "8   9\n",
       "9  10\n",
       "10 11\n",
       "11 12\n",
       "12 13\n",
       "13 14\n",
       "14 15\n",
       "15 16\n",
       "16 17\n",
       "17 18\n",
       "18 19\n",
       "19 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid1<-expand.grid(.k=seq(2,20,by=1))#k의 입력값을 위한 격자망\n",
    "grid1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "control= trainControl(method=\"cv\") #caret 매개변수 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k-Nearest Neighbors \n",
       "\n",
       "372 samples\n",
       "  7 predictor\n",
       "  2 classes: 'No', 'Yes' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 335, 335, 334, 335, 334, 336, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  k   Accuracy   Kappa    \n",
       "   2  0.7209380  0.3680320\n",
       "   3  0.7049471  0.3207223\n",
       "   4  0.7237316  0.3552936\n",
       "   5  0.7077960  0.3255223\n",
       "   6  0.7398095  0.4013436\n",
       "   7  0.7344713  0.3864556\n",
       "   8  0.7321993  0.3787563\n",
       "   9  0.7482693  0.4076722\n",
       "  10  0.7425004  0.4043236\n",
       "  11  0.7506085  0.4202276\n",
       "  12  0.7481231  0.4098386\n",
       "  13  0.7639837  0.4473478\n",
       "  14  0.7584361  0.4283687\n",
       "  15  0.7530307  0.4153831\n",
       "  16  0.7503951  0.4097321\n",
       "  17  0.7557334  0.4190032\n",
       "  18  0.7529595  0.4057878\n",
       "  19  0.7531018  0.4070139\n",
       "  20  0.7635570  0.4308925\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was k = 13."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123)\n",
    "knn.train<- train(type~., train, method=\"knn\", trControl=control, tuneGrid=grid1)   #caret 최적k 구하기\n",
    "knn.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "knn.test No Yes\n",
       "     No  91  22\n",
       "     Yes 16  31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn.test<- knn(train[,-8], test[, -8], train[,8], k=17)\n",
    "table(knn.test, test$type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for confusionMatrix {caret}\"><tr><td>confusionMatrix {caret}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Create a confusion matrix</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Calculates a cross-tabulation of observed and predicted classes with\n",
       "associated statistics.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "confusionMatrix(data, ...)\n",
       "\n",
       "## Default S3 method:\n",
       "confusionMatrix(\n",
       "  data,\n",
       "  reference,\n",
       "  positive = NULL,\n",
       "  dnn = c(\"Prediction\", \"Reference\"),\n",
       "  prevalence = NULL,\n",
       "  mode = \"sens_spec\",\n",
       "  ...\n",
       ")\n",
       "\n",
       "## S3 method for class 'table'\n",
       "confusionMatrix(\n",
       "  data,\n",
       "  positive = NULL,\n",
       "  prevalence = NULL,\n",
       "  mode = \"sens_spec\",\n",
       "  ...\n",
       ")\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>data</code></td>\n",
       "<td>\n",
       "<p>a factor of predicted classes (for the default method) or an\n",
       "object of class <code>table</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>options to be passed to <code>table</code>. NOTE: do not include\n",
       "<code>dnn</code> here</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>reference</code></td>\n",
       "<td>\n",
       "<p>a factor of classes to be used as the true results</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>positive</code></td>\n",
       "<td>\n",
       "<p>an optional character string for the factor level that\n",
       "corresponds to a &quot;positive&quot; result (if that makes sense for your data). If\n",
       "there are only two factor levels, the first level will be used as the\n",
       "&quot;positive&quot; result. When <code>mode = \"prec_recall\"</code>, <code>positive</code> is the\n",
       "same value used for <code>relevant</code> for functions <code>precision</code>,\n",
       "<code>recall</code>, and <code>F_meas.table</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>dnn</code></td>\n",
       "<td>\n",
       "<p>a character vector of dimnames for the table</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prevalence</code></td>\n",
       "<td>\n",
       "<p>a numeric value or matrix for the rate of the &quot;positive&quot;\n",
       "class of the data. When <code>data</code> has two levels, <code>prevalence</code> should\n",
       "be a single numeric value. Otherwise, it should be a vector of numeric\n",
       "values with elements for each class. The vector should have names\n",
       "corresponding to the classes.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mode</code></td>\n",
       "<td>\n",
       "<p>a single character string either &quot;sens_spec&quot;, &quot;prec_recall&quot;, or\n",
       "&quot;everything&quot;</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The functions requires that the factors have exactly the same levels.\n",
       "</p>\n",
       "<p>For two class problems, the sensitivity, specificity, positive predictive\n",
       "value and negative predictive value is calculated using the <code>positive</code>\n",
       "argument. Also, the prevalence of the &quot;event&quot; is computed from the data\n",
       "(unless passed in as an argument), the detection rate (the rate of true\n",
       "events also predicted to be events) and the detection prevalence (the\n",
       "prevalence of predicted events).\n",
       "</p>\n",
       "<p>Suppose a 2x2 table with notation\n",
       "</p>\n",
       "\n",
       "<table summary=\"Rd table\">\n",
       "<tr>\n",
       " <td style=\"text-align: right;\"> </td><td style=\"text-align: center;\"> Reference </td><td style=\"text-align: center;\"> </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\"> Predicted </td><td style=\"text-align: center;\"> Event </td><td style=\"text-align: center;\"> No Event\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\"> Event </td><td style=\"text-align: center;\"> A </td><td style=\"text-align: center;\"> B </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\"> No Event </td><td style=\"text-align: center;\"> C </td><td style=\"text-align: center;\"> D </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: right;\"> </td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "<p>The formulas used here are: </p>\n",
       "<p style=\"text-align: center;\"><i>Sensitivity = A/(A+C)</i></p>\n",
       " <p style=\"text-align: center;\"><i>Specificity =\n",
       "D/(B+D)</i></p>\n",
       " <p style=\"text-align: center;\"><i>Prevalence = (A+C)/(A+B+C+D)</i></p>\n",
       " <p style=\"text-align: center;\"><i>PPV = (sensitivity *\n",
       "prevalence)/((sensitivity*prevalence) + ((1-specificity)*(1-prevalence)))</i></p>\n",
       "\n",
       "<p style=\"text-align: center;\"><i>NPV = (specificity * (1-prevalence))/(((1-sensitivity)*prevalence) +\n",
       "((specificity)*(1-prevalence)))</i></p>\n",
       " <p style=\"text-align: center;\"><i>Detection Rate = A/(A+B+C+D)</i></p>\n",
       "\n",
       "<p style=\"text-align: center;\"><i>Detection Prevalence = (A+B)/(A+B+C+D)</i></p>\n",
       " <p style=\"text-align: center;\"><i>Balanced Accuracy =\n",
       "(sensitivity+specificity)/2</i></p>\n",
       "\n",
       "<p style=\"text-align: center;\"><i>Precision = A/(A+B)</i></p>\n",
       " <p style=\"text-align: center;\"><i>Recall = A/(A+C)</i></p>\n",
       " <p style=\"text-align: center;\"><i>F1 =\n",
       "(1+beta^2)*precision*recall/((beta^2 * precision)+recall)</i></p>\n",
       "\n",
       "<p>where <code>beta = 1</code> for this function.\n",
       "</p>\n",
       "<p>See the references for discussions of the first five formulas.\n",
       "</p>\n",
       "<p>For more than two classes, these results are calculated comparing each\n",
       "factor level to the remaining levels (i.e. a &quot;one versus all&quot; approach).\n",
       "</p>\n",
       "<p>The overall accuracy and unweighted Kappa statistic are calculated. A\n",
       "p-value from McNemar's test is also computed using\n",
       "<code>mcnemar.test</code> (which can produce <code>NA</code> values with\n",
       "sparse tables).\n",
       "</p>\n",
       "<p>The overall accuracy rate is computed along with a 95 percent confidence\n",
       "interval for this rate (using <code>binom.test</code>) and a\n",
       "one-sided test to see if the accuracy is better than the &quot;no information\n",
       "rate,&quot; which is taken to be the largest class percentage in the data.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>a list with elements </p>\n",
       "<table summary=\"R valueblock\">\n",
       "<tr valign=\"top\"><td><code>table</code></td>\n",
       "<td>\n",
       "<p>the results of <code>table</code> on\n",
       "<code>data</code> and <code>reference</code></p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>positive</code></td>\n",
       "<td>\n",
       "<p>the positive result level</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>overall</code></td>\n",
       "<td>\n",
       "<p>a numeric vector with overall accuracy and Kappa statistic\n",
       "values</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>byClass</code></td>\n",
       "<td>\n",
       "<p>the sensitivity, specificity, positive predictive\n",
       "value, negative predictive value, precision, recall, F1, prevalence,\n",
       "detection rate, detection prevalence and balanced accuracy for each class.\n",
       "For two class systems, this is calculated once using the <code>positive</code>\n",
       "argument</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>If the reference and data factors have the same levels, but in the\n",
       "incorrect order, the function will reorder them to the order of the data and\n",
       "issue a warning.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Max Kuhn\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Kuhn, M. (2008), &ldquo;Building predictive models in R using the\n",
       "caret package, &rdquo; <em>Journal of Statistical Software</em>,\n",
       "(<a href=\"http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf\">http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf</a>).\n",
       "</p>\n",
       "<p>Altman, D.G., Bland, J.M. (1994) &ldquo;Diagnostic tests 1: sensitivity and\n",
       "specificity,&rdquo; <em>British Medical Journal</em>, vol 308, 1552.\n",
       "</p>\n",
       "<p>Altman, D.G., Bland, J.M. (1994) &ldquo;Diagnostic tests 2: predictive values,&rdquo;\n",
       "<em>British Medical Journal</em>, vol 309, 102.\n",
       "</p>\n",
       "<p>Velez, D.R., et. al. (2008) &ldquo;A balanced accuracy function for epistasis\n",
       "modeling in imbalanced datasets using multifactor dimensionality\n",
       "reduction.,&rdquo; <em>Genetic Epidemiology</em>, vol 4, 306.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>as.table.confusionMatrix</code>,\n",
       "<code>as.matrix.confusionMatrix</code>, <code>sensitivity</code>,\n",
       "<code>specificity</code>, <code>posPredValue</code>,\n",
       "<code>negPredValue</code>, <code>print.confusionMatrix</code>,\n",
       "<code>binom.test</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "\n",
       "###################\n",
       "## 2 class example\n",
       "\n",
       "lvs &lt;- c(\"normal\", \"abnormal\")\n",
       "truth &lt;- factor(rep(lvs, times = c(86, 258)),\n",
       "                levels = rev(lvs))\n",
       "pred &lt;- factor(\n",
       "               c(\n",
       "                 rep(lvs, times = c(54, 32)),\n",
       "                 rep(lvs, times = c(27, 231))),\n",
       "               levels = rev(lvs))\n",
       "\n",
       "xtab &lt;- table(pred, truth)\n",
       "\n",
       "confusionMatrix(xtab)\n",
       "confusionMatrix(pred, truth)\n",
       "confusionMatrix(xtab, prevalence = 0.25)\n",
       "\n",
       "###################\n",
       "## 3 class example\n",
       "\n",
       "confusionMatrix(iris$Species, sample(iris$Species))\n",
       "\n",
       "newPrior &lt;- c(.05, .8, .15)\n",
       "names(newPrior) &lt;- levels(iris$Species)\n",
       "\n",
       "confusionMatrix(iris$Species, sample(iris$Species))\n",
       "\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>caret</em> version 6.0-86 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{confusionMatrix}{Create a confusion matrix}{confusionMatrix}\n",
       "\\methaliasA{confusionMatrix.default}{confusionMatrix}{confusionMatrix.default}\n",
       "\\methaliasA{confusionMatrix.table}{confusionMatrix}{confusionMatrix.table}\n",
       "\\keyword{utilities}{confusionMatrix}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Calculates a cross-tabulation of observed and predicted classes with\n",
       "associated statistics.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "confusionMatrix(data, ...)\n",
       "\n",
       "## Default S3 method:\n",
       "confusionMatrix(\n",
       "  data,\n",
       "  reference,\n",
       "  positive = NULL,\n",
       "  dnn = c(\"Prediction\", \"Reference\"),\n",
       "  prevalence = NULL,\n",
       "  mode = \"sens_spec\",\n",
       "  ...\n",
       ")\n",
       "\n",
       "## S3 method for class 'table'\n",
       "confusionMatrix(\n",
       "  data,\n",
       "  positive = NULL,\n",
       "  prevalence = NULL,\n",
       "  mode = \"sens_spec\",\n",
       "  ...\n",
       ")\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{data}] a factor of predicted classes (for the default method) or an\n",
       "object of class \\code{\\LinkA{table}{table}}.\n",
       "\n",
       "\\item[\\code{...}] options to be passed to \\code{table}. NOTE: do not include\n",
       "\\code{dnn} here\n",
       "\n",
       "\\item[\\code{reference}] a factor of classes to be used as the true results\n",
       "\n",
       "\\item[\\code{positive}] an optional character string for the factor level that\n",
       "corresponds to a \"positive\" result (if that makes sense for your data). If\n",
       "there are only two factor levels, the first level will be used as the\n",
       "\"positive\" result. When \\code{mode = \"prec\\_recall\"}, \\code{positive} is the\n",
       "same value used for \\code{relevant} for functions \\code{\\LinkA{precision}{precision}},\n",
       "\\code{\\LinkA{recall}{recall}}, and \\code{\\LinkA{F\\_meas.table}{F.Rul.meas.table}}.\n",
       "\n",
       "\\item[\\code{dnn}] a character vector of dimnames for the table\n",
       "\n",
       "\\item[\\code{prevalence}] a numeric value or matrix for the rate of the \"positive\"\n",
       "class of the data. When \\code{data} has two levels, \\code{prevalence} should\n",
       "be a single numeric value. Otherwise, it should be a vector of numeric\n",
       "values with elements for each class. The vector should have names\n",
       "corresponding to the classes.\n",
       "\n",
       "\\item[\\code{mode}] a single character string either \"sens\\_spec\", \"prec\\_recall\", or\n",
       "\"everything\"\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The functions requires that the factors have exactly the same levels.\n",
       "\n",
       "For two class problems, the sensitivity, specificity, positive predictive\n",
       "value and negative predictive value is calculated using the \\code{positive}\n",
       "argument. Also, the prevalence of the \"event\" is computed from the data\n",
       "(unless passed in as an argument), the detection rate (the rate of true\n",
       "events also predicted to be events) and the detection prevalence (the\n",
       "prevalence of predicted events).\n",
       "\n",
       "Suppose a 2x2 table with notation\n",
       "\n",
       "\n",
       "\\Tabular{rcc}{ & Reference & \\\\{} Predicted & Event & No Event\n",
       "\\\\{} Event & A & B \\\\{} No Event & C & D \\\\{} }\n",
       "\n",
       "The formulas used here are: \\deqn{Sensitivity = A/(A+C)}{} \\deqn{Specificity =\n",
       "D/(B+D)}{} \\deqn{Prevalence = (A+C)/(A+B+C+D)}{} \\deqn{PPV = (sensitivity *\n",
       "prevalence)/((sensitivity*prevalence) + ((1-specificity)*(1-prevalence)))}{}\n",
       "\\deqn{NPV = (specificity * (1-prevalence))/(((1-sensitivity)*prevalence) +\n",
       "((specificity)*(1-prevalence)))}{} \\deqn{Detection Rate = A/(A+B+C+D)}{}\n",
       "\\deqn{Detection Prevalence = (A+B)/(A+B+C+D)}{} \\deqn{Balanced Accuracy =\n",
       "(sensitivity+specificity)/2}{}\n",
       "\n",
       "\\deqn{Precision = A/(A+B)}{} \\deqn{Recall = A/(A+C)}{} \\deqn{F1 =\n",
       "(1+beta^2)*precision*recall/((beta^2 * precision)+recall)}{}\n",
       "\n",
       "where \\code{beta = 1} for this function.\n",
       "\n",
       "See the references for discussions of the first five formulas.\n",
       "\n",
       "For more than two classes, these results are calculated comparing each\n",
       "factor level to the remaining levels (i.e. a \"one versus all\" approach).\n",
       "\n",
       "The overall accuracy and unweighted Kappa statistic are calculated. A\n",
       "p-value from McNemar's test is also computed using\n",
       "\\code{\\LinkA{mcnemar.test}{mcnemar.test}} (which can produce \\code{NA} values with\n",
       "sparse tables).\n",
       "\n",
       "The overall accuracy rate is computed along with a 95 percent confidence\n",
       "interval for this rate (using \\code{\\LinkA{binom.test}{binom.test}}) and a\n",
       "one-sided test to see if the accuracy is better than the \"no information\n",
       "rate,\" which is taken to be the largest class percentage in the data.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "a list with elements \\begin{ldescription}\n",
       "\\item[\\code{table}] the results of \\code{table} on\n",
       "\\code{data} and \\code{reference}\\item[\\code{positive}] the positive result level\n",
       "\\item[\\code{overall}] a numeric vector with overall accuracy and Kappa statistic\n",
       "values\\item[\\code{byClass}] the sensitivity, specificity, positive predictive\n",
       "value, negative predictive value, precision, recall, F1, prevalence,\n",
       "detection rate, detection prevalence and balanced accuracy for each class.\n",
       "For two class systems, this is calculated once using the \\code{positive}\n",
       "argument\n",
       "\\end{ldescription}\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\\relax\n",
       "If the reference and data factors have the same levels, but in the\n",
       "incorrect order, the function will reorder them to the order of the data and\n",
       "issue a warning.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "Max Kuhn\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Kuhn, M. (2008), ``Building predictive models in R using the\n",
       "caret package, '' \\emph{Journal of Statistical Software},\n",
       "(\\url{http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf}).\n",
       "\n",
       "Altman, D.G., Bland, J.M. (1994) ``Diagnostic tests 1: sensitivity and\n",
       "specificity,'' \\emph{British Medical Journal}, vol 308, 1552.\n",
       "\n",
       "Altman, D.G., Bland, J.M. (1994) ``Diagnostic tests 2: predictive values,''\n",
       "\\emph{British Medical Journal}, vol 309, 102.\n",
       "\n",
       "Velez, D.R., et. al. (2008) ``A balanced accuracy function for epistasis\n",
       "modeling in imbalanced datasets using multifactor dimensionality\n",
       "reduction.,'' \\emph{Genetic Epidemiology}, vol 4, 306.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{as.table.confusionMatrix}{as.table.confusionMatrix}},\n",
       "\\code{\\LinkA{as.matrix.confusionMatrix}{as.matrix.confusionMatrix}}, \\code{\\LinkA{sensitivity}{sensitivity}},\n",
       "\\code{\\LinkA{specificity}{specificity}}, \\code{\\LinkA{posPredValue}{posPredValue}},\n",
       "\\code{\\LinkA{negPredValue}{negPredValue}}, \\code{\\LinkA{print.confusionMatrix}{print.confusionMatrix}},\n",
       "\\code{\\LinkA{binom.test}{binom.test}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "###################\n",
       "## 2 class example\n",
       "\n",
       "lvs <- c(\"normal\", \"abnormal\")\n",
       "truth <- factor(rep(lvs, times = c(86, 258)),\n",
       "                levels = rev(lvs))\n",
       "pred <- factor(\n",
       "               c(\n",
       "                 rep(lvs, times = c(54, 32)),\n",
       "                 rep(lvs, times = c(27, 231))),\n",
       "               levels = rev(lvs))\n",
       "\n",
       "xtab <- table(pred, truth)\n",
       "\n",
       "confusionMatrix(xtab)\n",
       "confusionMatrix(pred, truth)\n",
       "confusionMatrix(xtab, prevalence = 0.25)\n",
       "\n",
       "###################\n",
       "## 3 class example\n",
       "\n",
       "confusionMatrix(iris$Species, sample(iris$Species))\n",
       "\n",
       "newPrior <- c(.05, .8, .15)\n",
       "names(newPrior) <- levels(iris$Species)\n",
       "\n",
       "confusionMatrix(iris$Species, sample(iris$Species))\n",
       "\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "confusionMatrix             package:caret              R Documentation\n",
       "\n",
       "_\bC_\br_\be_\ba_\bt_\be _\ba _\bc_\bo_\bn_\bf_\bu_\bs_\bi_\bo_\bn _\bm_\ba_\bt_\br_\bi_\bx\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Calculates a cross-tabulation of observed and predicted classes\n",
       "     with associated statistics.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     confusionMatrix(data, ...)\n",
       "     \n",
       "     ## Default S3 method:\n",
       "     confusionMatrix(\n",
       "       data,\n",
       "       reference,\n",
       "       positive = NULL,\n",
       "       dnn = c(\"Prediction\", \"Reference\"),\n",
       "       prevalence = NULL,\n",
       "       mode = \"sens_spec\",\n",
       "       ...\n",
       "     )\n",
       "     \n",
       "     ## S3 method for class 'table'\n",
       "     confusionMatrix(\n",
       "       data,\n",
       "       positive = NULL,\n",
       "       prevalence = NULL,\n",
       "       mode = \"sens_spec\",\n",
       "       ...\n",
       "     )\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "    data: a factor of predicted classes (for the default method) or an\n",
       "          object of class 'table'.\n",
       "\n",
       "     ...: options to be passed to 'table'. NOTE: do not include 'dnn'\n",
       "          here\n",
       "\n",
       "reference: a factor of classes to be used as the true results\n",
       "\n",
       "positive: an optional character string for the factor level that\n",
       "          corresponds to a \"positive\" result (if that makes sense for\n",
       "          your data). If there are only two factor levels, the first\n",
       "          level will be used as the \"positive\" result. When 'mode =\n",
       "          \"prec_recall\"', 'positive' is the same value used for\n",
       "          'relevant' for functions 'precision', 'recall', and\n",
       "          'F_meas.table'.\n",
       "\n",
       "     dnn: a character vector of dimnames for the table\n",
       "\n",
       "prevalence: a numeric value or matrix for the rate of the \"positive\"\n",
       "          class of the data. When 'data' has two levels, 'prevalence'\n",
       "          should be a single numeric value. Otherwise, it should be a\n",
       "          vector of numeric values with elements for each class. The\n",
       "          vector should have names corresponding to the classes.\n",
       "\n",
       "    mode: a single character string either \"sens_spec\", \"prec_recall\",\n",
       "          or \"everything\"\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The functions requires that the factors have exactly the same\n",
       "     levels.\n",
       "\n",
       "     For two class problems, the sensitivity, specificity, positive\n",
       "     predictive value and negative predictive value is calculated using\n",
       "     the 'positive' argument. Also, the prevalence of the \"event\" is\n",
       "     computed from the data (unless passed in as an argument), the\n",
       "     detection rate (the rate of true events also predicted to be\n",
       "     events) and the detection prevalence (the prevalence of predicted\n",
       "     events).\n",
       "\n",
       "     Suppose a 2x2 table with notation\n",
       "\n",
       "                  Reference           \n",
       "       Predicted    Event    No Event \n",
       "           Event      A         B     \n",
       "        No Event      C         D     \n",
       "      \n",
       "     The formulas used here are:\n",
       "\n",
       "                            Sensitivity = A/(A+C)                       \n",
       "     \n",
       "                            Specificity =D/(B+D)                        \n",
       "     \n",
       "                        Prevalence = (A+C)/(A+B+C+D)                    \n",
       "     \n",
       "     PPV = (sensitivity *\n",
       "     prevalence)/((sensitivity*prevalence) + ((1-specificity)*(1-prevalence)))\n",
       "     \n",
       "     NPV = (specificity * (1-prevalence))/(((1-sensitivity)*prevalence) +\n",
       "     ((specificity)*(1-prevalence)))\n",
       "     \n",
       "                        Detection Rate = A/(A+B+C+D)                    \n",
       "     \n",
       "                   Detection Prevalence = (A+B)/(A+B+C+D)               \n",
       "     \n",
       "               Balanced Accuracy =(sensitivity+specificity)/2           \n",
       "     \n",
       "                             Precision = A/(A+B)                        \n",
       "     \n",
       "                              Recall = A/(A+C)                          \n",
       "     \n",
       "        F1 =(1+beta^2)*precision*recall/((beta^2 * precision)+recall)   \n",
       "     \n",
       "     where 'beta = 1' for this function.\n",
       "\n",
       "     See the references for discussions of the first five formulas.\n",
       "\n",
       "     For more than two classes, these results are calculated comparing\n",
       "     each factor level to the remaining levels (i.e. a \"one versus all\"\n",
       "     approach).\n",
       "\n",
       "     The overall accuracy and unweighted Kappa statistic are\n",
       "     calculated. A p-value from McNemar's test is also computed using\n",
       "     'mcnemar.test' (which can produce 'NA' values with sparse tables).\n",
       "\n",
       "     The overall accuracy rate is computed along with a 95 percent\n",
       "     confidence interval for this rate (using 'binom.test') and a\n",
       "     one-sided test to see if the accuracy is better than the \"no\n",
       "     information rate,\" which is taken to be the largest class\n",
       "     percentage in the data.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     a list with elements\n",
       "\n",
       "   table: the results of 'table' on 'data' and 'reference'\n",
       "\n",
       "positive: the positive result level\n",
       "\n",
       " overall: a numeric vector with overall accuracy and Kappa statistic\n",
       "          values\n",
       "\n",
       " byClass: the sensitivity, specificity, positive predictive value,\n",
       "          negative predictive value, precision, recall, F1, prevalence,\n",
       "          detection rate, detection prevalence and balanced accuracy\n",
       "          for each class. For two class systems, this is calculated\n",
       "          once using the 'positive' argument\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     If the reference and data factors have the same levels, but in the\n",
       "     incorrect order, the function will reorder them to the order of\n",
       "     the data and issue a warning.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Max Kuhn\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Kuhn, M. (2008), ``Building predictive models in R using the caret\n",
       "     package, '' _Journal of Statistical Software_, (<URL:\n",
       "     http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf>).\n",
       "\n",
       "     Altman, D.G., Bland, J.M. (1994) ``Diagnostic tests 1: sensitivity\n",
       "     and specificity,'' _British Medical Journal_, vol 308, 1552.\n",
       "\n",
       "     Altman, D.G., Bland, J.M. (1994) ``Diagnostic tests 2: predictive\n",
       "     values,'' _British Medical Journal_, vol 309, 102.\n",
       "\n",
       "     Velez, D.R., et. al. (2008) ``A balanced accuracy function for\n",
       "     epistasis modeling in imbalanced datasets using multifactor\n",
       "     dimensionality reduction.,'' _Genetic Epidemiology_, vol 4, 306.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     'as.table.confusionMatrix', 'as.matrix.confusionMatrix',\n",
       "     'sensitivity', 'specificity', 'posPredValue', 'negPredValue',\n",
       "     'print.confusionMatrix', 'binom.test'\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ###################\n",
       "     ## 2 class example\n",
       "     \n",
       "     lvs <- c(\"normal\", \"abnormal\")\n",
       "     truth <- factor(rep(lvs, times = c(86, 258)),\n",
       "                     levels = rev(lvs))\n",
       "     pred <- factor(\n",
       "                    c(\n",
       "                      rep(lvs, times = c(54, 32)),\n",
       "                      rep(lvs, times = c(27, 231))),\n",
       "                    levels = rev(lvs))\n",
       "     \n",
       "     xtab <- table(pred, truth)\n",
       "     \n",
       "     confusionMatrix(xtab)\n",
       "     confusionMatrix(pred, truth)\n",
       "     confusionMatrix(xtab, prevalence = 0.25)\n",
       "     \n",
       "     ###################\n",
       "     ## 3 class example\n",
       "     \n",
       "     confusionMatrix(iris$Species, sample(iris$Species))\n",
       "     \n",
       "     newPrior <- c(.05, .8, .15)\n",
       "     names(newPrior) <- levels(iris$Species)\n",
       "     \n",
       "     confusionMatrix(iris$Species, sample(iris$Species))\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  91  22\n",
       "       Yes 16  31\n",
       "                                          \n",
       "               Accuracy : 0.7625          \n",
       "                 95% CI : (0.6889, 0.8261)\n",
       "    No Information Rate : 0.6688          \n",
       "    P-Value [Acc > NIR] : 0.006336        \n",
       "                                          \n",
       "                  Kappa : 0.4482          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.417304        \n",
       "                                          \n",
       "            Sensitivity : 0.8505          \n",
       "            Specificity : 0.5849          \n",
       "         Pos Pred Value : 0.8053          \n",
       "         Neg Pred Value : 0.6596          \n",
       "             Prevalence : 0.6687          \n",
       "         Detection Rate : 0.5687          \n",
       "   Detection Prevalence : 0.7063          \n",
       "      Balanced Accuracy : 0.7177          \n",
       "                                          \n",
       "       'Positive' Class : No              \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(  knn.test    , test[,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAzQBNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123)\n",
    "kknn.train<-train.kknn(type~., train, kmax=25,distance=2, kernel=c(\"rectangular\", \"triangular\", \"epanechnikov\") )\n",
    "plot(kknn.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "train.kknn(formula = type ~ ., data = train, kmax = 25, distance = 2,     kernel = c(\"rectangular\", \"triangular\", \"epanechnikov\"))\n",
       "\n",
       "Type of response variable: nominal\n",
       "Minimal misclassification: 0.233871\n",
       "Best kernel: rectangular\n",
       "Best k: 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kknn.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  92  22\n",
       "       Yes 15  31\n",
       "                                          \n",
       "               Accuracy : 0.7688          \n",
       "                 95% CI : (0.6956, 0.8317)\n",
       "    No Information Rate : 0.6688          \n",
       "    P-Value [Acc > NIR] : 0.003774        \n",
       "                                          \n",
       "                  Kappa : 0.4601          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.323940        \n",
       "                                          \n",
       "            Sensitivity : 0.8598          \n",
       "            Specificity : 0.5849          \n",
       "         Pos Pred Value : 0.8070          \n",
       "         Neg Pred Value : 0.6739          \n",
       "             Prevalence : 0.6687          \n",
       "         Detection Rate : 0.5750          \n",
       "   Detection Prevalence : 0.7125          \n",
       "      Balanced Accuracy : 0.7224          \n",
       "                                          \n",
       "       'Positive' Class : No              \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.kknn<-predict(kknn.train, test)\n",
    "confusionMatrix(pred.kknn, test[,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "kknn.train <- train.kknn(type ~ ., data = train, \n",
    "                         kmax = 25, distance = 2, \n",
    "                         kernel = c(\"rectangular\", \"triangular\", \"epanechnikov\")\n",
    "#k쵀대값, 거리=1(유클리드),2(절댓값합)\n",
    "plot(kknn.train)\n",
    "kknn.train\n",
    "kknn.pred <- predict(kknn.train, newdata = test)\n",
    "table(kknn.pred, test$type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 서포트벡터머신 모형화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'e1071' was built under R version 3.6.3\"\n",
      "Attaching package: 'kernlab'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    alpha\n",
      "\n",
      "Warning message:\n",
      "\"package 'pROC' was built under R version 3.6.3\"Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "Attaching package: 'pROC'\n",
      "\n",
      "The following object is masked from 'package:h2o':\n",
      "\n",
      "    var\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(e1071)  #SVM\n",
    "library(kernlab) #SVM피처 선택에 도움   ksvm \n",
    "library(pROC) # SVM 피처 선택에 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " cost\n",
       " 0.01\n",
       "\n",
       "- best performance: 0.2253201 \n",
       "\n",
       "- Detailed performance results:\n",
       "   cost     error dispersion\n",
       "1 1e-03 0.3328592 0.07520531\n",
       "2 1e-02 0.2253201 0.05398517\n",
       "3 1e-01 0.2308677 0.05814214\n",
       "4 5e+00 0.2335704 0.05211775\n",
       "5 1e+01 0.2335704 0.05211775\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123)\n",
    "linear.tune<- tune.svm(type~., data=train, kernel=\"linear\", cost=c(0.001, 0.01, 0.1, 5, 10))\n",
    "summary(linear.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 8\n",
      " $ best.parameters :'data.frame':\t1 obs. of  1 variable:\n",
      "  ..$ cost: num 0.01\n",
      "  ..- attr(*, \"out.attrs\")=List of 2\n",
      "  .. ..$ dim     : Named int 5\n",
      "  .. .. ..- attr(*, \"names\")= chr \"cost\"\n",
      "  .. ..$ dimnames:List of 1\n",
      "  .. .. ..$ cost: chr [1:5] \"cost=1e-03\" \"cost=1e-02\" \"cost=1e-01\" \"cost=5e+00\" ...\n",
      " $ best.performance: num 0.225\n",
      " $ method          : chr \"svm\"\n",
      " $ nparcomb        : int 5\n",
      " $ train.ind       :List of 10\n",
      "  ..$ (0.629,38.1]: int [1:334] 166 217 290 69 72 76 63 141 210 363 ...\n",
      "  ..$ (38.1,75.2] : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (75.2,112]  : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (112,149]   : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (149,186]   : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (186,224]   : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (224,261]   : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (261,298]   : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (298,335]   : int [1:335] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..$ (335,372]   : int [1:334] 179 14 195 306 118 299 229 244 371 153 ...\n",
      "  ..- attr(*, \"dim\")= int 10\n",
      "  ..- attr(*, \"dimnames\")=List of 1\n",
      "  .. ..$ : chr [1:10] \"(0.629,38.1]\" \"(38.1,75.2]\" \"(75.2,112]\" \"(112,149]\" ...\n",
      " $ sampling        : chr \"10-fold cross validation\"\n",
      " $ performances    :'data.frame':\t5 obs. of  3 variables:\n",
      "  ..$ cost      : num [1:5] 1e-03 1e-02 1e-01 5e+00 1e+01\n",
      "  ..$ error     : num [1:5] 0.333 0.225 0.231 0.234 0.234\n",
      "  ..$ dispersion: num [1:5] 0.0752 0.054 0.0581 0.0521 0.0521\n",
      " $ best.model      :List of 30\n",
      "  ..$ call           : language best.svm(x = type ~ ., data = train, cost = c(0.001, 0.01, 0.1, 5, 10),      kernel = \"linear\")\n",
      "  ..$ type           : num 0\n",
      "  ..$ kernel         : num 0\n",
      "  ..$ cost           : num 0.01\n",
      "  ..$ degree         : num 3\n",
      "  ..$ gamma          : num 0.143\n",
      "  ..$ coef0          : num 0\n",
      "  ..$ nu             : num 0.5\n",
      "  ..$ epsilon        : num 0.1\n",
      "  ..$ sparse         : logi FALSE\n",
      "  ..$ scaled         : logi [1:7] TRUE TRUE TRUE TRUE TRUE TRUE ...\n",
      "  ..$ x.scale        :List of 2\n",
      "  .. ..$ scaled:center: Named num [1:7] -0.046501 0.000331 -0.090863 0.006685 0.025329 ...\n",
      "  .. .. ..- attr(*, \"names\")= chr [1:7] \"npreg\" \"glu\" \"bp\" \"skin\" ...\n",
      "  .. ..$ scaled:scale : Named num [1:7] 0.968 0.994 1.013 0.962 1.006 ...\n",
      "  .. .. ..- attr(*, \"names\")= chr [1:7] \"npreg\" \"glu\" \"bp\" \"skin\" ...\n",
      "  ..$ y.scale        : NULL\n",
      "  ..$ nclasses       : int 2\n",
      "  ..$ levels         : chr [1:2] \"No\" \"Yes\"\n",
      "  ..$ tot.nSV        : int 233\n",
      "  ..$ nSV            : int [1:2] 116 117\n",
      "  ..$ labels         : int [1:2] 1 2\n",
      "  ..$ SV             : num [1:233, 1:7] 1.134 0.199 0.511 3.006 -0.425 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr [1:233] \"132\" \"397\" \"264\" \"520\" ...\n",
      "  .. .. ..$ : chr [1:7] \"npreg\" \"glu\" \"bp\" \"skin\" ...\n",
      "  ..$ index          : int [1:233] 1 6 7 12 23 24 25 26 31 32 ...\n",
      "  ..$ rho            : num -0.599\n",
      "  ..$ compprob       : logi FALSE\n",
      "  ..$ probA          : NULL\n",
      "  ..$ probB          : NULL\n",
      "  ..$ sigma          : NULL\n",
      "  ..$ coefs          : num [1:233, 1] 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 ...\n",
      "  ..$ na.action      : NULL\n",
      "  ..$ fitted         : Factor w/ 2 levels \"No\",\"Yes\": 2 1 1 1 1 1 1 1 1 1 ...\n",
      "  .. ..- attr(*, \"names\")= chr [1:372] \"132\" \"42\" \"133\" \"193\" ...\n",
      "  ..$ decision.values: num [1:372, 1] -1.065 1.301 1.283 0.383 1.578 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr [1:372] \"132\" \"42\" \"133\" \"193\" ...\n",
      "  .. .. ..$ : chr \"No/Yes\"\n",
      "  ..$ terms          :Classes 'terms', 'formula'  language type ~ npreg + glu + bp + skin + bmi + ped + age\n",
      "  .. .. ..- attr(*, \"variables\")= language list(type, npreg, glu, bp, skin, bmi, ped, age)\n",
      "  .. .. ..- attr(*, \"factors\")= int [1:8, 1:7] 0 1 0 0 0 0 0 0 0 0 ...\n",
      "  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. .. .. ..$ : chr [1:8] \"type\" \"npreg\" \"glu\" \"bp\" ...\n",
      "  .. .. .. .. ..$ : chr [1:7] \"npreg\" \"glu\" \"bp\" \"skin\" ...\n",
      "  .. .. ..- attr(*, \"term.labels\")= chr [1:7] \"npreg\" \"glu\" \"bp\" \"skin\" ...\n",
      "  .. .. ..- attr(*, \"order\")= int [1:7] 1 1 1 1 1 1 1\n",
      "  .. .. ..- attr(*, \"intercept\")= num 0\n",
      "  .. .. ..- attr(*, \"response\")= int 1\n",
      "  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n",
      "  .. .. ..- attr(*, \"predvars\")= language list(type, npreg, glu, bp, skin, bmi, ped, age)\n",
      "  .. .. ..- attr(*, \"dataClasses\")= Named chr [1:8] \"factor\" \"numeric\" \"numeric\" \"numeric\" ...\n",
      "  .. .. .. ..- attr(*, \"names\")= chr [1:8] \"type\" \"npreg\" \"glu\" \"bp\" ...\n",
      "  ..- attr(*, \"class\")= chr [1:2] \"svm.formula\" \"svm\"\n",
      " - attr(*, \"class\")= chr \"tune\"\n"
     ]
    }
   ],
   "source": [
    "str(linear.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.linear<- predict( linear.tune$best.model , test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  99  22\n",
       "       Yes  8  31\n",
       "                                          \n",
       "               Accuracy : 0.8125          \n",
       "                 95% CI : (0.7433, 0.8698)\n",
       "    No Information Rate : 0.6688          \n",
       "    P-Value [Acc > NIR] : 3.856e-05       \n",
       "                                          \n",
       "                  Kappa : 0.5466          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.01762         \n",
       "                                          \n",
       "            Sensitivity : 0.9252          \n",
       "            Specificity : 0.5849          \n",
       "         Pos Pred Value : 0.8182          \n",
       "         Neg Pred Value : 0.7949          \n",
       "             Prevalence : 0.6687          \n",
       "         Detection Rate : 0.6188          \n",
       "   Detection Prevalence : 0.7562          \n",
       "      Balanced Accuracy : 0.7551          \n",
       "                                          \n",
       "       'Positive' Class : No              \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(pred.linear, test$type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.8125"
      ],
      "text/latex": [
       "0.8125"
      ],
      "text/markdown": [
       "0.8125"
      ],
      "text/plain": [
       "[1] 0.8125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(99+31)/( 99 + 22 + 8 +31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " degree coef0\n",
       "      4     1\n",
       "\n",
       "- best performance: 0.247155 \n",
       "\n",
       "- Detailed performance results:\n",
       "   degree coef0     error dispersion\n",
       "1       3   0.1 0.2551209 0.05112128\n",
       "2       4   0.1 0.2794452 0.04679591\n",
       "3       5   0.1 0.2580370 0.05095140\n",
       "4       3   0.5 0.2577525 0.05050198\n",
       "5       4   0.5 0.2578947 0.05291403\n",
       "6       5   0.5 0.2607397 0.04205493\n",
       "7       3   1.0 0.2497866 0.05241520\n",
       "8       4   1.0 0.2471550 0.07072851\n",
       "9       5   1.0 0.2738976 0.08062815\n",
       "10      3   2.0 0.2525605 0.04988188\n",
       "11      4   2.0 0.2498578 0.08857378\n",
       "12      5   2.0 0.2978663 0.08102477\n",
       "13      3   3.0 0.2551209 0.04933760\n",
       "14      4   3.0 0.2578236 0.08651490\n",
       "15      5   3.0 0.3272404 0.10012853\n",
       "16      3   4.0 0.2524182 0.04747560\n",
       "17      4   4.0 0.2578236 0.07761384\n",
       "18      5   4.0 0.3113798 0.09290467\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SVM with e1071; tune the poly only\n",
    "set.seed(123)\n",
    "poly.tune<-tune.svm(type~., data=train, kernel=\"polynomial\", degree=c(3,4,5), coef0=c(0.1, 0.5, 1, 2, 3, 4))\n",
    "summary(poly.tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  91  25\n",
       "       Yes 16  28\n",
       "                                          \n",
       "               Accuracy : 0.7438          \n",
       "                 95% CI : (0.6688, 0.8094)\n",
       "    No Information Rate : 0.6688          \n",
       "    P-Value [Acc > NIR] : 0.02487         \n",
       "                                          \n",
       "                  Kappa : 0.3957          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.21152         \n",
       "                                          \n",
       "            Sensitivity : 0.5283          \n",
       "            Specificity : 0.8505          \n",
       "         Pos Pred Value : 0.6364          \n",
       "         Neg Pred Value : 0.7845          \n",
       "             Prevalence : 0.3312          \n",
       "         Detection Rate : 0.1750          \n",
       "   Detection Prevalence : 0.2750          \n",
       "      Balanced Accuracy : 0.6894          \n",
       "                                          \n",
       "       'Positive' Class : Yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.poly<-predict(poly.tune$best.model, test)\n",
    "confusionMatrix(pred.poly, test[,8], positive='Yes')   # 성능 안좋아짐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t160 obs. of  8 variables:\n",
      " $ npreg: num  -1.062 -0.76 0.146 2.259 -1.062 ...\n",
      " $ glu  : num  -0.453 -1.13 -0.711 0.709 0.58 ...\n",
      " $ bp   : num  -0.935 -0.447 0.365 1.827 -0.772 ...\n",
      " $ skin : num  -0.397 2.168 -1.348 0.363 -1.158 ...\n",
      " $ bmi  : num  -0.943 1.222 -1.408 0.539 -1.568 ...\n",
      " $ ped  : num  -1.074 1.202 -0.813 -0.723 -0.859 ...\n",
      " $ age  : num  -0.801 -0.243 -0.986 1.801 -0.986 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 2 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for tune.wrapper {e1071}\"><tr><td>tune.wrapper {e1071}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Convenience Tuning Wrapper Functions</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Convenience tuning wrapper functions, using <code>tune</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "tune.svm(x, y = NULL, data = NULL, degree = NULL, gamma = NULL, coef0 = NULL,\n",
       "         cost = NULL, nu = NULL, class.weights = NULL, epsilon = NULL, ...)\n",
       "best.svm(x, tunecontrol = tune.control(), ...)\n",
       " \n",
       "tune.nnet(x, y = NULL, data = NULL, size = NULL, decay = NULL,\n",
       "          trace = FALSE, tunecontrol = tune.control(nrepeat = 5), \n",
       "          ...)\n",
       "best.nnet(x, tunecontrol = tune.control(nrepeat = 5), ...)\n",
       "\n",
       "tune.rpart(formula, data, na.action = na.omit, minsplit = NULL,\n",
       "           minbucket = NULL, cp = NULL, maxcompete = NULL, maxsurrogate = NULL,\n",
       "           usesurrogate = NULL, xval = NULL, surrogatestyle = NULL, maxdepth =\n",
       "           NULL, predict.func = NULL, ...)\n",
       "best.rpart(formula, tunecontrol = tune.control(), ...)\n",
       "\n",
       "tune.randomForest(x, y = NULL, data = NULL, nodesize = NULL, \n",
       "                  mtry = NULL, ntree = NULL, ...)\n",
       "best.randomForest(x, tunecontrol = tune.control(), ...)\n",
       "\n",
       "tune.knn(x, y, k = NULL, l = NULL, ...) \n",
       "\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>formula, x, y, data</code></td>\n",
       "<td>\n",
       "<p>formula and data arguments of function to be tuned.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>predict.func</code></td>\n",
       "<td>\n",
       "<p>predicting function.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.action</code></td>\n",
       "<td>\n",
       "<p>function handling missingness.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>minsplit, minbucket, cp, maxcompete,\n",
       "maxsurrogate, usesurrogate, xval,\n",
       "surrogatestyle, maxdepth</code></td>\n",
       "<td>\n",
       "<p><code>rpart</code> parameters.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>degree, gamma, coef0, cost, nu, class.weights, epsilon</code></td>\n",
       "<td>\n",
       "<p><code>svm</code>\n",
       "parameters.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>k, l</code></td>\n",
       "<td>\n",
       "<p><code>knn</code> parameters.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mtry, nodesize, ntree</code></td>\n",
       "<td>\n",
       "<p><code>randomForest</code> parameters.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>size, decay, trace</code></td>\n",
       "<td>\n",
       "<p>parameters passed to\n",
       "<code>nnet</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>tunecontrol</code></td>\n",
       "<td>\n",
       "<p>object of class <code>\"tune.control\"</code> containing\n",
       "tuning parameters.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Further parameters passed to <code>tune</code>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>For examples, see the help page of <code>tune()</code>.</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p><code>tune.foo()</code> returns a tuning object including the best parameter set obtained\n",
       "by optimizing over the specified parameter vectors. <code>best.foo()</code>\n",
       "directly returns the best model, i.e. the fit of a new model using the\n",
       "optimal parameters found by <code>tune.foo</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>David Meyer<br />\n",
       "<a href=\"mailto:David.Meyer@R-project.org\">David.Meyer@R-project.org</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>tune</code></p>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>e1071</em> version 1.7-6 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{tune.wrapper}{Convenience Tuning Wrapper Functions}{tune.wrapper}\n",
       "\\aliasA{best.nnet}{tune.wrapper}{best.nnet}\n",
       "\\aliasA{best.randomForest}{tune.wrapper}{best.randomForest}\n",
       "\\aliasA{best.rpart}{tune.wrapper}{best.rpart}\n",
       "\\aliasA{best.svm}{tune.wrapper}{best.svm}\n",
       "\\aliasA{tune.knn}{tune.wrapper}{tune.knn}\n",
       "\\aliasA{tune.nnet}{tune.wrapper}{tune.nnet}\n",
       "\\aliasA{tune.randomForest}{tune.wrapper}{tune.randomForest}\n",
       "\\aliasA{tune.rpart}{tune.wrapper}{tune.rpart}\n",
       "\\aliasA{tune.svm}{tune.wrapper}{tune.svm}\n",
       "\\keyword{models}{tune.wrapper}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Convenience tuning wrapper functions, using \\code{tune}.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "tune.svm(x, y = NULL, data = NULL, degree = NULL, gamma = NULL, coef0 = NULL,\n",
       "         cost = NULL, nu = NULL, class.weights = NULL, epsilon = NULL, ...)\n",
       "best.svm(x, tunecontrol = tune.control(), ...)\n",
       " \n",
       "tune.nnet(x, y = NULL, data = NULL, size = NULL, decay = NULL,\n",
       "          trace = FALSE, tunecontrol = tune.control(nrepeat = 5), \n",
       "          ...)\n",
       "best.nnet(x, tunecontrol = tune.control(nrepeat = 5), ...)\n",
       "\n",
       "tune.rpart(formula, data, na.action = na.omit, minsplit = NULL,\n",
       "           minbucket = NULL, cp = NULL, maxcompete = NULL, maxsurrogate = NULL,\n",
       "           usesurrogate = NULL, xval = NULL, surrogatestyle = NULL, maxdepth =\n",
       "           NULL, predict.func = NULL, ...)\n",
       "best.rpart(formula, tunecontrol = tune.control(), ...)\n",
       "\n",
       "tune.randomForest(x, y = NULL, data = NULL, nodesize = NULL, \n",
       "                  mtry = NULL, ntree = NULL, ...)\n",
       "best.randomForest(x, tunecontrol = tune.control(), ...)\n",
       "\n",
       "tune.knn(x, y, k = NULL, l = NULL, ...) \n",
       "\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{formula, x, y, data}] formula and data arguments of function to be tuned.\n",
       "\\item[\\code{predict.func}] predicting function.\n",
       "\\item[\\code{na.action}] function handling missingness.\n",
       "\\item[\\code{minsplit, minbucket, cp, maxcompete,\n",
       "maxsurrogate, usesurrogate, xval,\n",
       "surrogatestyle, maxdepth}] \\code{rpart} parameters.\n",
       "\\item[\\code{degree, gamma, coef0, cost, nu, class.weights, epsilon}] \\code{svm}\n",
       "parameters.\n",
       "\\item[\\code{k, l}] \\code{knn} parameters.\n",
       "\\item[\\code{mtry, nodesize, ntree}] \\code{randomForest} parameters.\n",
       "\\item[\\code{size, decay, trace}] parameters passed to\n",
       "\\code{nnet}.\n",
       "\\item[\\code{tunecontrol}] object of class \\code{\"tune.control\"} containing\n",
       "tuning parameters.\n",
       "\\item[\\code{...}] Further parameters passed to \\code{tune}.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "For examples, see the help page of \\code{tune()}.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "\\code{tune.foo()} returns a tuning object including the best parameter set obtained\n",
       "by optimizing over the specified parameter vectors. \\code{best.foo()}\n",
       "directly returns the best model, i.e. the fit of a new model using the\n",
       "optimal parameters found by \\code{tune.foo}.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "David Meyer\\\\{}\n",
       "\\email{David.Meyer@R-project.org}\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{tune}{tune}}\n",
       "\\end{SeeAlso}"
      ],
      "text/plain": [
       "tune.wrapper               package:e1071               R Documentation\n",
       "\n",
       "_\bC_\bo_\bn_\bv_\be_\bn_\bi_\be_\bn_\bc_\be _\bT_\bu_\bn_\bi_\bn_\bg _\bW_\br_\ba_\bp_\bp_\be_\br _\bF_\bu_\bn_\bc_\bt_\bi_\bo_\bn_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Convenience tuning wrapper functions, using 'tune'.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     tune.svm(x, y = NULL, data = NULL, degree = NULL, gamma = NULL, coef0 = NULL,\n",
       "              cost = NULL, nu = NULL, class.weights = NULL, epsilon = NULL, ...)\n",
       "     best.svm(x, tunecontrol = tune.control(), ...)\n",
       "      \n",
       "     tune.nnet(x, y = NULL, data = NULL, size = NULL, decay = NULL,\n",
       "               trace = FALSE, tunecontrol = tune.control(nrepeat = 5), \n",
       "               ...)\n",
       "     best.nnet(x, tunecontrol = tune.control(nrepeat = 5), ...)\n",
       "     \n",
       "     tune.rpart(formula, data, na.action = na.omit, minsplit = NULL,\n",
       "                minbucket = NULL, cp = NULL, maxcompete = NULL, maxsurrogate = NULL,\n",
       "                usesurrogate = NULL, xval = NULL, surrogatestyle = NULL, maxdepth =\n",
       "                NULL, predict.func = NULL, ...)\n",
       "     best.rpart(formula, tunecontrol = tune.control(), ...)\n",
       "     \n",
       "     tune.randomForest(x, y = NULL, data = NULL, nodesize = NULL, \n",
       "                       mtry = NULL, ntree = NULL, ...)\n",
       "     best.randomForest(x, tunecontrol = tune.control(), ...)\n",
       "     \n",
       "     tune.knn(x, y, k = NULL, l = NULL, ...) \n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "formula, x, y, data: formula and data arguments of function to be\n",
       "          tuned.\n",
       "\n",
       "predict.func: predicting function.\n",
       "\n",
       "na.action: function handling missingness.\n",
       "\n",
       "minsplit, minbucket, cp, maxcompete,: maxsurrogate, usesurrogate,\n",
       "          xval,: surrogatestyle, maxdepth: 'rpart' parameters.\n",
       "\n",
       "degree, gamma, coef0, cost, nu, class.weights, epsilon: 'svm'\n",
       "          parameters.\n",
       "\n",
       "    k, l: 'knn' parameters.\n",
       "\n",
       "mtry, nodesize, ntree: 'randomForest' parameters.\n",
       "\n",
       "size, decay, trace: parameters passed to 'nnet'.\n",
       "\n",
       "tunecontrol: object of class '\"tune.control\"' containing tuning\n",
       "          parameters.\n",
       "\n",
       "     ...: Further parameters passed to 'tune'.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     For examples, see the help page of 'tune()'.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     'tune.foo()' returns a tuning object including the best parameter\n",
       "     set obtained by optimizing over the specified parameter vectors.\n",
       "     'best.foo()' directly returns the best model, i.e. the fit of a\n",
       "     new model using the optimal parameters found by 'tune.foo'.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     David Meyer\n",
       "     <email: David.Meyer@R-project.org>\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     'tune'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tune.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in UseMethod(\"predict\"): 클래스 \"tune\"의 객체에 적용된 'predict'에 사용할수 있는 메소드가 없습니다\n",
     "output_type": "error",
     "traceback": [
      "Error in UseMethod(\"predict\"): 클래스 \"tune\"의 객체에 적용된 'predict'에 사용할수 있는 메소드가 없습니다\nTraceback:\n",
      "1. sapply(cost, function(x) {\n .     set.seed(123)\n .     m <- tune.svm(type ~ ., data = train, kernel = \"sigmoid\", \n .         coef0 = x)\n .     pred <- predict(m, test)\n .     agree <- ifelse(pred == test$type, 1, 0)\n .     accu <- sum(agree)/nrow(test$type)\n .     return(accu)\n . })",
      "2. lapply(X = X, FUN = FUN, ...)",
      "3. FUN(X[[i]], ...)",
      "4. predict(m, test)   # at line 6 of file <text>",
      "5. predict(m, test)"
     ]
    }
   ],
   "source": [
    "cost<- c(1, seq(from = 5, to = 40, by = 5))\n",
    "\n",
    "accu <- sapply(cost, function(x) {\n",
    "        set.seed(123)\n",
    "        m<-tune.svm(type~., data=train, kernel=\"sigmoid\", coef0=x    )\n",
    "        pred <- predict(m, test)\n",
    "        agree <- ifelse(pred == test$type, 1, 0)\n",
    "        accu <- sum(agree) / nrow(test$type)\n",
    "        return (accu)\n",
    "        })\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cost, accu, type = \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t372 obs. of  8 variables:\n",
      " $ npreg: num  1.05 -0.76 0.75 -0.76 -0.76 ...\n",
      " $ glu  : num  1.87 -0.775 -1.324 0.225 -1.098 ...\n",
      " $ bp   : num  1.909 -0.285 -0.447 -1.909 0.528 ...\n",
      " $ skin : num  0.1727 -0.7775 0.0777 1.503 -0.2074 ...\n",
      " $ bmi  : num  0.19 -0.827 -0.972 1.106 0.248 ...\n",
      " $ ped  : num  -0.984 1.718 -0.551 0.319 -1.167 ...\n",
      " $ age  : num  2.638 -0.893 0.872 -0.708 -0.893 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t372 obs. of  8 variables:\n",
      " $ npreg: num  1.05 -0.76 0.75 -0.76 -0.76 ...\n",
      " $ glu  : num  1.87 -0.775 -1.324 0.225 -1.098 ...\n",
      " $ bp   : num  1.909 -0.285 -0.447 -1.909 0.528 ...\n",
      " $ skin : num  0.1727 -0.7775 0.0777 1.503 -0.2074 ...\n",
      " $ bmi  : num  0.19 -0.827 -0.972 1.106 0.248 ...\n",
      " $ ped  : num  -0.984 1.718 -0.551 0.319 -1.167 ...\n",
      " $ age  : num  2.638 -0.893 0.872 -0.708 -0.893 ...\n",
      " $ type : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " gamma\n",
       "   0.1\n",
       "\n",
       "- best performance: 0.2523471 \n",
       "\n",
       "- Detailed performance results:\n",
       "  gamma     error dispersion\n",
       "1   0.1 0.2523471 0.06132776\n",
       "2   0.5 0.2658606 0.06709869\n",
       "3   1.0 0.2955192 0.09778431\n",
       "4   2.0 0.3435277 0.08293300\n",
       "5   3.0 0.3328592 0.07075692\n",
       "6   4.0 0.3328592 0.07520531\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tune the rbf\n",
    "set.seed(123)\n",
    "rbf.tune<-tune.svm(type~., data=train, kernel=\"radial\", gamma=c(0.1, 0.5, 1, 2, 3, 4))\n",
    "summary(rbf.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " gamma coef0\n",
       "   0.1   0.1\n",
       "\n",
       "- best performance: 0.2523471 \n",
       "\n",
       "- Detailed performance results:\n",
       "   gamma coef0     error dispersion\n",
       "1    0.1   0.1 0.2523471 0.06132776\n",
       "2    0.5   0.1 0.2658606 0.06709869\n",
       "3    1.0   0.1 0.2955192 0.09778431\n",
       "4    2.0   0.1 0.3435277 0.08293300\n",
       "5    3.0   0.1 0.3328592 0.07075692\n",
       "6    4.0   0.1 0.3328592 0.07520531\n",
       "7    0.1   0.5 0.2523471 0.06132776\n",
       "8    0.5   0.5 0.2658606 0.06709869\n",
       "9    1.0   0.5 0.2955192 0.09778431\n",
       "10   2.0   0.5 0.3435277 0.08293300\n",
       "11   3.0   0.5 0.3328592 0.07075692\n",
       "12   4.0   0.5 0.3328592 0.07520531\n",
       "13   0.1   1.0 0.2523471 0.06132776\n",
       "14   0.5   1.0 0.2658606 0.06709869\n",
       "15   1.0   1.0 0.2955192 0.09778431\n",
       "16   2.0   1.0 0.3435277 0.08293300\n",
       "17   3.0   1.0 0.3328592 0.07075692\n",
       "18   4.0   1.0 0.3328592 0.07520531\n",
       "19   0.1   2.0 0.2523471 0.06132776\n",
       "20   0.5   2.0 0.2658606 0.06709869\n",
       "21   1.0   2.0 0.2955192 0.09778431\n",
       "22   2.0   2.0 0.3435277 0.08293300\n",
       "23   3.0   2.0 0.3328592 0.07075692\n",
       "24   4.0   2.0 0.3328592 0.07520531\n",
       "25   0.1   3.0 0.2523471 0.06132776\n",
       "26   0.5   3.0 0.2658606 0.06709869\n",
       "27   1.0   3.0 0.2955192 0.09778431\n",
       "28   2.0   3.0 0.3435277 0.08293300\n",
       "29   3.0   3.0 0.3328592 0.07075692\n",
       "30   4.0   3.0 0.3328592 0.07520531\n",
       "31   0.1   4.0 0.2523471 0.06132776\n",
       "32   0.5   4.0 0.2658606 0.06709869\n",
       "33   1.0   4.0 0.2955192 0.09778431\n",
       "34   2.0   4.0 0.3435277 0.08293300\n",
       "35   3.0   4.0 0.3328592 0.07075692\n",
       "36   4.0   4.0 0.3328592 0.07520531\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123)\n",
    "rbf.tune2<-tune.svm(type~., data=train, kernel=\"radial\", gamma=c(0.1, 0.5, 1, 2, 3, 4), coef0=c(0.1, 0.5, 1, 2, 3, 4))\n",
    "summary(rbf.tune2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  92  18\n",
       "       Yes 15  35\n",
       "                                          \n",
       "               Accuracy : 0.7938          \n",
       "                 95% CI : (0.7227, 0.8536)\n",
       "    No Information Rate : 0.6688          \n",
       "    P-Value [Acc > NIR] : 0.0003407       \n",
       "                                          \n",
       "                  Kappa : 0.5277          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.7277235       \n",
       "                                          \n",
       "            Sensitivity : 0.8598          \n",
       "            Specificity : 0.6604          \n",
       "         Pos Pred Value : 0.8364          \n",
       "         Neg Pred Value : 0.7000          \n",
       "             Prevalence : 0.6687          \n",
       "         Detection Rate : 0.5750          \n",
       "   Detection Prevalence : 0.6875          \n",
       "      Balanced Accuracy : 0.7601          \n",
       "                                          \n",
       "       'Positive' Class : No              \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.rbf<-predict(rbf.tune$best.model, test)\n",
    "confusionMatrix(pred.rbf, test[,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the sigmoid\n",
    "set.seed(123)\n",
    "sigmoid.tune<-tune.svm(type~., data=train, kernel=\"sigmoid\", gamma=c(0.1, 0.5, 1,2,3,4), coef0 = c(0.1, 0.5, 1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " gamma coef0\n",
       "   0.1   0.1\n",
       "\n",
       "- best performance: 0.2229018 \n",
       "\n",
       "- Detailed performance results:\n",
       "   gamma coef0     error dispersion\n",
       "1    0.1   0.1 0.2229018 0.05860528\n",
       "2    0.5   0.1 0.3169275 0.07454714\n",
       "3    1.0   0.1 0.3275960 0.06938948\n",
       "4    2.0   0.1 0.3384780 0.07628827\n",
       "5    3.0   0.1 0.3438122 0.07764059\n",
       "6    4.0   0.1 0.3493599 0.07571836\n",
       "7    0.1   0.5 0.2766714 0.04423798\n",
       "8    0.5   0.5 0.3062589 0.08172612\n",
       "9    1.0   0.5 0.3305121 0.05738301\n",
       "10   2.0   0.5 0.3492888 0.06724232\n",
       "11   3.0   0.5 0.3332148 0.06559450\n",
       "12   4.0   0.5 0.3546230 0.06306770\n",
       "13   0.1   1.0 0.2901849 0.05855424\n",
       "14   0.5   1.0 0.3359175 0.03742256\n",
       "15   1.0   1.0 0.3279516 0.05931762\n",
       "16   2.0   1.0 0.3522760 0.06486276\n",
       "17   3.0   1.0 0.3493599 0.06152541\n",
       "18   4.0   1.0 0.3628023 0.06569827\n",
       "19   0.1   2.0 0.2255334 0.03623273\n",
       "20   0.5   2.0 0.3816501 0.06252709\n",
       "21   1.0   2.0 0.3788051 0.03820463\n",
       "22   2.0   2.0 0.3225462 0.06948584\n",
       "23   3.0   2.0 0.3361309 0.06692624\n",
       "24   4.0   2.0 0.3414651 0.06651451\n",
       "25   0.1   3.0 0.3328592 0.07520531\n",
       "26   0.5   3.0 0.4057610 0.07469556\n",
       "27   1.0   3.0 0.3817923 0.05554113\n",
       "28   2.0   3.0 0.3251778 0.07305179\n",
       "29   3.0   3.0 0.3387624 0.06155121\n",
       "30   4.0   3.0 0.3441679 0.06105832\n",
       "31   0.1   4.0 0.3328592 0.07520531\n",
       "32   0.5   4.0 0.3977240 0.06481400\n",
       "33   1.0   4.0 0.3923898 0.06653783\n",
       "34   2.0   4.0 0.3760313 0.04928973\n",
       "35   3.0   4.0 0.3385491 0.03665462\n",
       "36   4.0   4.0 0.3438122 0.08055893\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(sigmoid.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.sigmoid<-predict(sigmoid.tune$best.model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  95  20\n",
       "       Yes 12  33\n",
       "                                         \n",
       "               Accuracy : 0.8            \n",
       "                 95% CI : (0.7296, 0.859)\n",
       "    No Information Rate : 0.6688         \n",
       "    P-Value [Acc > NIR] : 0.0001711      \n",
       "                                         \n",
       "                  Kappa : 0.5307         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.2159249      \n",
       "                                         \n",
       "            Sensitivity : 0.6226         \n",
       "            Specificity : 0.8879         \n",
       "         Pos Pred Value : 0.7333         \n",
       "         Neg Pred Value : 0.8261         \n",
       "             Prevalence : 0.3312         \n",
       "         Detection Rate : 0.2062         \n",
       "   Detection Prevalence : 0.2812         \n",
       "      Balanced Accuracy : 0.7552         \n",
       "                                         \n",
       "       'Positive' Class : Yes            \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  99  22\n",
       "       Yes  8  31\n",
       "                                          \n",
       "               Accuracy : 0.8125          \n",
       "                 95% CI : (0.7433, 0.8698)\n",
       "    No Information Rate : 0.6688          \n",
       "    P-Value [Acc > NIR] : 3.856e-05       \n",
       "                                          \n",
       "                  Kappa : 0.5466          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.01762         \n",
       "                                          \n",
       "            Sensitivity : 0.5849          \n",
       "            Specificity : 0.9252          \n",
       "         Pos Pred Value : 0.7949          \n",
       "         Neg Pred Value : 0.8182          \n",
       "             Prevalence : 0.3312          \n",
       "         Detection Rate : 0.1938          \n",
       "   Detection Prevalence : 0.2437          \n",
       "      Balanced Accuracy : 0.7551          \n",
       "                                          \n",
       "       'Positive' Class : Yes             \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "confusionMatrix(pred.sigmoid, test[,8], positive=\"Yes\")\n",
    "confusionMatrix(pred.linear, test[,8], positive = \"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Recursive feature selection\n",
       "\n",
       "Outer resampling method: Cross-Validated (10 fold) \n",
       "\n",
       "Resampling performance over subset size:\n",
       "\n",
       " Variables Accuracy  Kappa AccuracySD KappaSD Selected\n",
       "         4   0.7642 0.4406    0.07528  0.1766         \n",
       "         5   0.7667 0.4509    0.06124  0.1372        *\n",
       "         6   0.7586 0.4319    0.05546  0.1219         \n",
       "         7   0.7559 0.4246    0.05881  0.1307         \n",
       "\n",
       "The top 5 variables (out of 5):\n",
       "   glu, bmi, age, ped, npreg\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123)\n",
    "rfeCNTL<-rfeControl(functions=lrFuncs, method=\"cv\", number=10)   # caret, 교차 검증 방법 명시\n",
    "svm.features<-rfe(train[,1:7], train[,8], sizes=c(7,6,5,4), rfeControl=rfeCNTL, method=\"svmLinear\") #반복적 피처 선택 실행\n",
    "svm.features    # 변수 5개일때 accuracy 제일 높음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction No Yes\n",
       "       No  95  20\n",
       "       Yes 12  33\n",
       "                                         \n",
       "               Accuracy : 0.8            \n",
       "                 95% CI : (0.7296, 0.859)\n",
       "    No Information Rate : 0.6688         \n",
       "    P-Value [Acc > NIR] : 0.0001711      \n",
       "                                         \n",
       "                  Kappa : 0.5307         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.2159249      \n",
       "                                         \n",
       "            Sensitivity : 0.6226         \n",
       "            Specificity : 0.8879         \n",
       "         Pos Pred Value : 0.7333         \n",
       "         Neg Pred Value : 0.8261         \n",
       "             Prevalence : 0.3312         \n",
       "         Detection Rate : 0.2062         \n",
       "   Detection Prevalence : 0.2812         \n",
       "      Balanced Accuracy : 0.7552         \n",
       "                                         \n",
       "       'Positive' Class : Yes            \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm5<-svm(type~ glu+ped+ npreg + bmi + age, train, kernel=\"linear\")\n",
    "pred.svm5<-predict(svm5, test[c(1,2,5,6,7)])   # !!주의\n",
    "confusionMatrix(pred.svm5, test[,8], positive=\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm.5 <- svm(type ~ glu + ped + npreg + bmi + age, \n",
    "             data = train, \n",
    "             kernel = \"linear\")\n",
    "svm.5.predict = predict(svm.5, newdata=test[c(1,2,5,6,7)])\n",
    "table(svm.5.predict, test$type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adp실기책 svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"C:/Users/alsdu/Downloads/PART 05 실습용 데이터\")\n",
    "credit<-read.table(\"credit_final.csv\", header=T, sep=',')\n",
    "idx<-sample(3, nrow(credit), replace=T, prob=c(0.5, 0.3, 0.2))\n",
    "train<-credit[idx==1,]\n",
    "validation<-credit[idx==2,]\n",
    "test<-credit[idx==3,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.svm<-tune.svm(credit.rating~., data=credit, gamma = 10^(-6:-1), cost = 10^(1:2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of 'svm':\n",
       "\n",
       "- sampling method: 10-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " gamma cost\n",
       "  0.01   10\n",
       "\n",
       "- best performance: 0.1770652 \n",
       "\n",
       "- Detailed performance results:\n",
       "   gamma cost     error dispersion\n",
       "1  1e-06   10 0.2740612 0.03374569\n",
       "2  1e-05   10 0.2695580 0.03329187\n",
       "3  1e-04   10 0.2442154 0.03132812\n",
       "4  1e-03   10 0.2150317 0.02978270\n",
       "5  1e-02   10 0.1770652 0.03943902\n",
       "6  1e-01   10 0.1946432 0.03779258\n",
       "7  1e-06  100 0.2695661 0.03330019\n",
       "8  1e-05  100 0.2442731 0.03126381\n",
       "9  1e-04  100 0.2250110 0.03052894\n",
       "10 1e-03  100 0.1815764 0.03496832\n",
       "11 1e-02  100 0.2037425 0.04458852\n",
       "12 1e-01  100 0.2048385 0.03857783\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(tune.svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "svm(formula = credit.rating ~ ., data = train, kernel = \"radial\", \n",
       "    gamma = 0.01, cost = 10)\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  eps-regression \n",
       " SVM-Kernel:  radial \n",
       "       cost:  10 \n",
       "      gamma:  0.01 \n",
       "    epsilon:  0.1 \n",
       "\n",
       "\n",
       "Number of Support Vectors:  409\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm.model<-svm(credit.rating~., \n",
    "               data=train,\n",
    "               kernel=\"radial\",\n",
    "               gamma=0.01,\n",
    "               cost=10)\n",
    "\n",
    "summary(svm.model)\n",
    "\n",
    "pred.svm<-predict(svm.model,test,type=\"class\")                          #test 데이터로 예측값과 정확도를 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      \n",
       "pred.svm               0 1\n",
       "  -0.496664140333123   1 0\n",
       "  -0.00790331889503049 1 0\n",
       "  0.0454917246252952   0 1\n",
       "  0.0549839814085035   1 0\n",
       "  0.0685752008271824   1 0\n",
       "  0.10242224566308     0 1\n",
       "  0.107964737421451    1 0\n",
       "  0.133519365252856    1 0\n",
       "  0.142193433038159    1 0\n",
       "  0.151775882185284    1 0\n",
       "  0.167941928635832    1 0\n",
       "  0.225779819560729    0 1\n",
       "  0.243924294886474    0 1\n",
       "  0.250937301480006    1 0\n",
       "  0.2753396969359      1 0\n",
       "  0.279727228094879    1 0\n",
       "  0.280070652787014    1 0\n",
       "  0.299860828974848    1 0\n",
       "  0.32005067879656     1 0\n",
       "  0.339002383378541    0 1\n",
       "  0.339431705029509    0 1\n",
       "  0.347643283108821    1 0\n",
       "  0.34791978130612     1 0\n",
       "  0.350028355129783    0 1\n",
       "  0.35078629907398     0 1\n",
       "  0.392549548707817    1 0\n",
       "  0.400077282948064    0 1\n",
       "  0.401759242466683    0 1\n",
       "  0.409730017999546    0 1\n",
       "  0.414657798474298    1 0\n",
       "  0.417676741267585    1 0\n",
       "  0.444864574650111    1 0\n",
       "  0.453925734099032    1 0\n",
       "  0.460035504567447    1 0\n",
       "  0.492091812032837    0 1\n",
       "  0.49306233628887     1 0\n",
       "  0.497930274982512    0 1\n",
       "  0.498708171239026    0 1\n",
       "  0.510199450820674    0 1\n",
       "  0.511096526386632    1 0\n",
       "  0.511894700223661    0 1\n",
       "  0.533248300755029    0 1\n",
       "  0.533759561435973    0 1\n",
       "  0.549435030244666    0 1\n",
       "  0.559877582574671    0 1\n",
       "  0.561673837428747    0 1\n",
       "  0.561749055879896    1 0\n",
       "  0.572843476143862    0 1\n",
       "  0.573665215526129    1 0\n",
       "  0.579261847615859    1 0\n",
       "  0.580472851369453    0 1\n",
       "  0.581271596841509    0 1\n",
       "  0.581898928534724    0 1\n",
       "  0.593169984694816    0 1\n",
       "  0.593216272261288    1 0\n",
       "  0.604173636205286    0 1\n",
       "  0.604333099357832    0 1\n",
       "  0.613159499199875    0 1\n",
       "  0.614116285043911    0 1\n",
       "  0.619945708166105    1 0\n",
       "  0.625523058954809    0 1\n",
       "  0.627128811697531    0 1\n",
       "  0.660645573484084    0 1\n",
       "  0.661659191341862    0 1\n",
       "  0.670030187604297    0 1\n",
       "  0.682596245631729    1 0\n",
       "  0.686719860555646    0 1\n",
       "  0.687672098398629    0 1\n",
       "  0.693215654255209    1 0\n",
       "  0.700070986475103    0 1\n",
       "  0.70552864001371     0 1\n",
       "  0.711112154140969    0 1\n",
       "  0.71721297279172     1 0\n",
       "  0.71855187316442     1 0\n",
       "  0.721791108126195    1 0\n",
       "  0.728819112964677    0 1\n",
       "  0.729195714969219    0 1\n",
       "  0.729921685078628    0 1\n",
       "  0.733261183314541    0 1\n",
       "  0.734057844247039    0 1\n",
       "  0.739453518790313    0 1\n",
       "  0.758576581808384    1 0\n",
       "  0.758969116701965    0 1\n",
       "  0.767874536701951    0 1\n",
       "  0.771694160348446    0 1\n",
       "  0.775484375478467    0 1\n",
       "  0.783291829095384    1 0\n",
       "  0.786356420354512    0 1\n",
       "  0.799032505286169    0 1\n",
       "  0.805590174907724    0 1\n",
       "  0.808896764516494    0 1\n",
       "  0.812682377925333    0 1\n",
       "  0.812772814885441    0 1\n",
       "  0.813474697312046    0 1\n",
       "  0.837835461701496    0 1\n",
       "  0.843055583590337    0 1\n",
       "  0.845011012052745    1 0\n",
       "  0.846369417717701    1 0\n",
       "  0.847852972350397    0 1\n",
       "  0.847861150906806    0 1\n",
       "  0.848474623244598    0 1\n",
       "  0.850389040601732    1 0\n",
       "  0.85052487433809     0 1\n",
       "  0.856689162561068    0 1\n",
       "  0.860501069751231    0 1\n",
       "  0.860575836740715    1 0\n",
       "  0.862605407802787    1 0\n",
       "  0.86398410165201     0 1\n",
       "  0.864157252243731    0 1\n",
       "  0.871139411994719    0 1\n",
       "  0.875815207454015    0 1\n",
       "  0.881109830112117    0 1\n",
       "  0.881490326243478    0 1\n",
       "  0.884597248589625    0 1\n",
       "  0.887665278723928    0 1\n",
       "  0.888414639940085    1 0\n",
       "  0.890299749268385    0 1\n",
       "  0.895955807734232    0 1\n",
       "  0.895959621521516    1 0\n",
       "  0.901653757294674    0 1\n",
       "  0.903182790007619    0 1\n",
       "  0.903857723340796    0 1\n",
       "  0.907777630933888    0 1\n",
       "  0.909903715853493    0 1\n",
       "  0.910358513951752    0 1\n",
       "  0.910656638152622    1 0\n",
       "  0.912937171453627    0 1\n",
       "  0.913849568576475    0 1\n",
       "  0.919940434089685    0 1\n",
       "  0.921558952228063    0 1\n",
       "  0.925455453484493    0 1\n",
       "  0.934095540874319    0 1\n",
       "  0.934597847172248    1 0\n",
       "  0.934798652780736    0 1\n",
       "  0.934953902959709    1 0\n",
       "  0.936462140091218    0 1\n",
       "  0.936583173106835    0 1\n",
       "  0.936786575046563    1 0\n",
       "  0.943876876253276    0 1\n",
       "  0.944687977109383    0 1\n",
       "  0.946388071208775    0 1\n",
       "  0.94744617185464     0 1\n",
       "  0.951928401135236    0 1\n",
       "  0.957067454571014    0 1\n",
       "  0.957251373514225    0 1\n",
       "  0.967529104861552    0 1\n",
       "  0.968073595217383    0 1\n",
       "  0.969320153773314    0 1\n",
       "  0.970335051271176    0 1\n",
       "  0.971902523069003    1 0\n",
       "  0.980565107133941    0 1\n",
       "  0.982686891158506    0 1\n",
       "  0.986194271448586    0 1\n",
       "  0.994200690079051    1 0\n",
       "  0.997214558533226    0 1\n",
       "  0.998218375660928    0 1\n",
       "  1.00410537383724     0 1\n",
       "  1.01397675706747     0 1\n",
       "  1.01400928680378     0 1\n",
       "  1.0144778693462      0 1\n",
       "  1.02474284125386     0 1\n",
       "  1.02590900088117     0 1\n",
       "  1.02596748736487     0 1\n",
       "  1.03168588178592     0 1\n",
       "  1.03286588035232     0 1\n",
       "  1.04418079683019     0 1\n",
       "  1.05038125344202     0 1\n",
       "  1.05179757434142     1 0\n",
       "  1.05337722507167     0 1\n",
       "  1.05643813282833     0 1\n",
       "  1.06308063279714     0 1\n",
       "  1.0686193827013      0 1\n",
       "  1.07405320805711     0 1\n",
       "  1.0743532293833      0 1\n",
       "  1.07613677448321     0 1\n",
       "  1.07945607509896     0 1\n",
       "  1.08033075654039     0 1\n",
       "  1.08464536511299     0 1\n",
       "  1.08471679815506     0 1\n",
       "  1.08544269603291     1 0\n",
       "  1.08856134122175     1 0\n",
       "  1.11163923479399     0 1\n",
       "  1.11332525315214     0 1\n",
       "  1.11739588240667     1 0\n",
       "  1.11788461472479     0 1\n",
       "  1.12142639891206     0 1\n",
       "  1.12537968703366     0 1\n",
       "  1.12998825160861     0 1\n",
       "  1.13253839417356     1 0\n",
       "  1.13379749866033     1 0\n",
       "  1.13758865943944     0 1\n",
       "  1.15478952038411     0 1\n",
       "  1.15494106395794     1 0\n",
       "  1.1704983167949      0 1\n",
       "  1.19335969362782     1 0\n",
       "  1.21131214501668     0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(pred.svm,test[,1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       " 58 138 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table( test[,1] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: `data` and `reference` should be factors with the same levels.\n",
     "output_type": "error",
     "traceback": [
      "Error: `data` and `reference` should be factors with the same levels.\nTraceback:\n",
      "1. confusionMatrix(data = pred.svm, test[, 1], positive = \"1\")",
      "2. confusionMatrix.default(data = pred.svm, test[, 1], positive = \"1\")",
      "3. stop(\"`data` and `reference` should be factors with the same levels.\", \n .     call. = FALSE)"
     ]
    }
   ],
   "source": [
    "confusionMatrix(data=pred.svm, test[,1], positive='1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.svm<-predict(svm.model,test,type=\"class\")                          #test 데이터로 예측값과 정확도를 확인.\n",
    "table(pred.svm,test[,1])                      \n",
    "\n",
    "\n",
    "confusionMatrix(data=pred.svm, test[,1], positive='1')\n",
    "\n",
    "pred.svm.roc<-prediction(as.numeric(pred.svm),as.numeric(test[,1]))\n",
    "\n",
    "plot(performance(pred.svm.roc,\"tpr\",\"fpr\"))          #ROC Curve 작성.\n",
    "\n",
    "abline(a=0,b=1,lty=2,col=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) svm 모델 만들기\n",
    "#\n",
    "# svm(formula, \n",
    "#     data, \n",
    "#     kernel,        #훈련과 예측에 사용되는 커널로, \"radial\",\"linear\",\"polynomial\",\"sigmoid\"가 있음\n",
    "#                    #실제 문제에서 커널의 선택이 결과의 정확도에 큰 영향을 주지 않음\n",
    "#     gamma,         #초평면의 기울기, default=1/(데이터 차원)\n",
    "#     cost,          #과적합을 막는 정도, default=1\n",
    "#     ...)\n",
    "\n",
    "\n",
    "# 2) 파라미터 최적값 찾기 : svm에서는 gamma, cost 값을 가짐. cost는 과적합을 막는 정도를 지정하는 파라미터이며,\n",
    "#                           gamma는 초평면의 기울기를 의미.\n",
    "# tune.svm(formula, \n",
    "#          data, \n",
    "#          gamma,           #gamma값을 입력\n",
    "#          cost)            #cost값을 입력\n",
    "\n",
    "# ex) credit 데이터로 파라미터 최적값을 찾아 보자.\n",
    "\n",
    "setwd(\"C:/Users/alsdu/Downloads/PART 05 실습용 데이터\")\n",
    "credit<-read.table(\"credit_final.csv\", header=T, sep=',')\n",
    "idx<-sample(3, nrow(credit), replace=T, prob=c(0.5, 0.3, 0.2))\n",
    "train<-credit[idx==1,]\n",
    "validation<-credit[idx==2,]\n",
    "test<-credit[idx==3,]\n",
    "install.packages(\"e1071\")\n",
    "library(e1071)\n",
    "\n",
    "tune.svm(credit.rating~., \n",
    "         data=credit, \n",
    "         gamma = 10^(-6:-1),        \n",
    "         cost = 10^(1:2))          \n",
    "\n",
    "svm.model<-svm(credit.rating~., \n",
    "               data=train,\n",
    "               kernel=\"radial\",\n",
    "               gamma=0.01,\n",
    "               cost=10)\n",
    "\n",
    "summary(svm.model)\n",
    "\n",
    "pred.svm<-predict(svm.model,test,type=\"class\")                          #test 데이터로 예측값과 정확도를 확인.\n",
    "table(pred.svm,test[,1])                      \n",
    "\n",
    "confusionMatrix(data=pred.svm, reference=test[,1], positive='1')\n",
    "\n",
    "pred.svm.roc<-prediction(as.numeric(pred.svm),as.numeric(test[,1]))\n",
    "plot(performance(pred.svm.roc,\"tpr\",\"fpr\"))          #ROC Curve 작성.\n",
    "abline(a=0,b=1,lty=2,col=\"black\")                \n",
    "performance(pred.svm.roc,\"auc\")@y.values             #auc값이 50%로 성능이 좋지않음.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
